{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q08y-gtv4dDY",
        "outputId": "3fbd93ae-73e6-4653-ce04-478f70ee6e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Because Colab's environment:\n",
        "#    Gets reset every time the session ends\n",
        "#    Deletes all files when you disconnect\n",
        "#So mounting Drive allows your work to be saved permanently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vxMKLBBB6vsN"
      },
      "outputs": [],
      "source": [
        "SAVE_DIR = \"/content/drive/MyDrive/cifar10_data/\"\n",
        "import os\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UXiNxnq4lh8",
        "outputId": "41f88750-acca-4588-e9b1-4940316075f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 1. Imports & Device\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ======"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCPVYNoT4pDU",
        "outputId": "8e5ba24d-9c8e-4379-c629-05f9fa436319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size (32): 50000\n",
            "Test dataset size (32): 10000\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 2. CIFAR-10 Dataset & DataLoaders\n",
        "# ============================================================\n",
        "\n",
        "# --- 32×32 transform (for SimpleCNN & ResNet18_Scratch) ---\n",
        "transform_32 = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=(0.4914, 0.4822, 0.4465),\n",
        "        std=(0.2470, 0.2435, 0.2616)\n",
        "    )\n",
        "])\n",
        "\n",
        "# --- 224×224 transform (for pretrained ResNet18) ---\n",
        "weights = ResNet18_Weights.DEFAULT\n",
        "imagenet_transforms = weights.transforms()   # has Resize, CenterCrop, ToTensor, Normalize\n",
        "\n",
        "# If we want explicit:\n",
        "# transform_224 = transforms.Compose([\n",
        "#     transforms.Resize(224),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=weights.transforms().mean,\n",
        "#                          std=weights.transforms().std)\n",
        "# ])\n",
        "\n",
        "transform_224 = imagenet_transforms  # easiest: use built-in pipeline\n",
        "\n",
        "# --- Datasets ---\n",
        "train_dataset_32 = torchvision.datasets.CIFAR10(\n",
        "    root=SAVE_DIR, train=True, download=True, transform=transform_32\n",
        ")\n",
        "test_dataset_32 = torchvision.datasets.CIFAR10(\n",
        "    root=SAVE_DIR, train=False, download=True, transform=transform_32\n",
        ")\n",
        "\n",
        "# For the 224×224 model we can reuse the same CIFAR10, just different transform:\n",
        "train_dataset_224 = torchvision.datasets.CIFAR10(\n",
        "    root=SAVE_DIR, train=True, download=False, transform=transform_224\n",
        ")\n",
        "test_dataset_224 = torchvision.datasets.CIFAR10(\n",
        "    root=SAVE_DIR, train=False, download=False, transform=transform_224\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader_32 = DataLoader(train_dataset_32, batch_size=batch_size,\n",
        "                             shuffle=True, num_workers=2)\n",
        "test_loader_32 = DataLoader(test_dataset_32, batch_size=batch_size,\n",
        "                            shuffle=False, num_workers=2)\n",
        "\n",
        "train_loader_224 = DataLoader(train_dataset_224, batch_size=batch_size,\n",
        "                              shuffle=True, num_workers=2)\n",
        "test_loader_224 = DataLoader(test_dataset_224, batch_size=batch_size,\n",
        "                             shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print(f\"Training dataset size (32): {len(train_dataset_32)}\")\n",
        "print(f\"Test dataset size (32): {len(test_dataset_32)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights"
      ],
      "metadata": {
        "id": "ZN0iF7rvL3yw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i4GQRDJ5O5D",
        "outputId": "8cf7eb01-0957-4933-bc6e-39b0558d7ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SimpleCNN architecture:\n",
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc): Linear(in_features=800, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "ResNet18_Scratch_32 architecture:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): Identity()\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "ResNet18_Pretrained_224 architecture:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 3. Models: SimpleCNN, ResNet18 for CIFAR-10, and Pretrained ResNet18\n",
        "# ============================================================\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Conv1: (3, 32, 32) -> (16, 28, 28)\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=16,\n",
        "            kernel_size=5, stride=1, padding=0\n",
        "        )\n",
        "\n",
        "        # Conv2: (16, 14, 14) -> (32, 10, 10)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=16, out_channels=32,\n",
        "            kernel_size=5, stride=1, padding=0\n",
        "        )\n",
        "\n",
        "        # Max pooling (2×2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # FC: 32*5*5 -> 10\n",
        "        self.fc = nn.Linear(32 * 5 * 5, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv1 + ReLU + Pool: (3,32,32) -> (16,14,14)\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        # Conv2 + ReLU + Pool: (16,14,14) -> (32,5,5)\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)   # (batch, 32*5*5)\n",
        "        # FC to logits\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def create_resnet18_for_cifar10(num_classes=10):\n",
        "    \"\"\"\n",
        "    ResNet18 adapted for 32x32 CIFAR-10:\n",
        "      - small first conv (3x3, stride 1, padding 1)\n",
        "      - remove initial maxpool\n",
        "      - change final FC to num_classes\n",
        "      - no pretraining (weights=None) for fair comparison\n",
        "    \"\"\"\n",
        "    net = resnet18(weights=None)  # from scratch\n",
        "\n",
        "    # Adapt first conv & remove maxpool\n",
        "    net.conv1 = nn.Conv2d(\n",
        "        3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
        "    )\n",
        "    net.maxpool = nn.Identity() # The images are already tiny, No pooling, No pooling, No shrinking\n",
        "\n",
        "    # Change classifier head to CIFAR-10\n",
        "    net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
        "    return net\n",
        "\n",
        "\n",
        "def create_resnet18_pretrained_imagenet(num_classes=10, freeze_backbone=False):\n",
        "    \"\"\"\n",
        "    ResNet18 with ImageNet pretrained weights.\n",
        "    Expects 224x224 inputs with ImageNet-style transforms.\n",
        "    \"\"\"\n",
        "    net = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "    # Replace final FC layer for CIFAR-10\n",
        "    in_features = net.fc.in_features\n",
        "    net.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    return net\n",
        "\n",
        "\n",
        "# Create all three models\n",
        "models_dict = {\n",
        "    \"SimpleCNN\":              SimpleCNN().to(device),\n",
        "    \"ResNet18_Scratch_32\":    create_resnet18_for_cifar10().to(device),\n",
        "    \"ResNet18_Pretrained_224\": create_resnet18_pretrained_imagenet().to(device)\n",
        "}\n",
        "\n",
        "for name, m in models_dict.items():\n",
        "    print(f\"\\n{name} architecture:\")\n",
        "    print(m)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0MZFwy1JPrn1"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 4. Training Helper\n",
        "# ============================================================\n",
        "\n",
        "def train_model(model, optimizer, criterion,\n",
        "                train_loader, val_loader,\n",
        "                epochs=5, device=\"cuda\"):\n",
        "\n",
        "    history = {\"train_loss\": [], \"val_acc\": []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad() #Clears old gradients from the previous batch so they don't accumulate\n",
        "            outputs = model(images) #Forward pass: send input images through the model to get predictions\n",
        "            loss = criterion(outputs, labels) #Compute the loss (difference between model predictions and true labels)\n",
        "            loss.backward() #Backpropagation: compute gradients of loss with respect to model parameters\n",
        "            optimizer.step() #Update model parameters using the gradients\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        history[\"train_loss\"].append(avg_loss)\n",
        "\n",
        "        # ----- Validation phase  ----- (evaluation during training)\n",
        "        val_acc = evaluate_model(model, val_loader, device=device)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}  \"\n",
        "              f\"Loss: {avg_loss:.4f}  Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 5. Evaluation Helper\n",
        "# ============================================================\n",
        "def evaluate_model(model, loader, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad(): #Turn off gradient\n",
        "          for images, labels in loader:\n",
        "              images, labels = images.to(device), labels.to(device) #Move data to GPU\n",
        "\n",
        "              outputs = model(images) #Forward pass: get prediction scores\n",
        "              preds = torch.argmax(outputs, dim=1) #Pick the class with the highest score for each image\n",
        "              correct += (preds == labels).sum().item() #Count how many predictions match the true labels\n",
        "              total += labels.size(0) #Count total number of labels in this batch\n",
        "\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "pEYpMuQZTV4s"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GupvEAqt5WBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c224929-616f-4365-ccbe-88b574511fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Training model: SimpleCNN\n",
            "======================================================================\n",
            "Epoch 1/5  Loss: 0.7619  Val Acc: 0.6864\n",
            "Epoch 2/5  Loss: 0.7458  Val Acc: 0.6873\n",
            "Epoch 3/5  Loss: 0.7251  Val Acc: 0.6781\n",
            "Epoch 4/5  Loss: 0.7156  Val Acc: 0.6943\n",
            "Epoch 5/5  Loss: 0.7060  Val Acc: 0.6953\n",
            "\n",
            "======================================================================\n",
            "Training model: ResNet18_Scratch_32\n",
            "======================================================================\n",
            "Epoch 1/5  Loss: 0.0778  Val Acc: 0.8352\n",
            "Epoch 2/5  Loss: 0.0562  Val Acc: 0.8296\n",
            "Epoch 3/5  Loss: 0.0566  Val Acc: 0.8374\n",
            "Epoch 4/5  Loss: 0.0446  Val Acc: 0.8316\n",
            "Epoch 5/5  Loss: 0.0473  Val Acc: 0.8488\n",
            "\n",
            "======================================================================\n",
            "Training model: ResNet18_Pretrained_224\n",
            "======================================================================\n",
            "Epoch 1/5  Loss: 0.1216  Val Acc: 0.8833\n",
            "Epoch 2/5  Loss: 0.0840  Val Acc: 0.8930\n",
            "Epoch 3/5  Loss: 0.0733  Val Acc: 0.8953\n",
            "Epoch 4/5  Loss: 0.0660  Val Acc: 0.8972\n",
            "Epoch 5/5  Loss: 0.0496  Val Acc: 0.9035\n",
            "\n",
            "Final test accuracies:\n",
            "Model: SimpleCNN\n",
            "SimpleCNN: 0.6953\n",
            "Model: ResNet18_Scratch_32\n",
            "ResNet18_Scratch_32: 0.8488\n",
            "Model: ResNet18_Pretrained_224\n",
            "ResNet18_Pretrained_224: 0.9035\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 6. Train all three models\n",
        "# ============================================================\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models_dict.items():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"Training model: {model_name}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Choose loaders based on model\n",
        "    if model_name == \"ResNet18_Pretrained_224\":\n",
        "        train_loader = train_loader_224\n",
        "        val_loader = test_loader_224\n",
        "    else:\n",
        "        train_loader = train_loader_32\n",
        "        val_loader = test_loader_32\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    history = train_model(model, optimizer, criterion,\n",
        "                          train_loader, val_loader,\n",
        "                          epochs=5, device=device)\n",
        "\n",
        "    results[model_name] = history\n",
        "\n",
        "\n",
        "\n",
        "# After training: report final test accuracy for each model\n",
        "print(\"\\nFinal test accuracies:\")\n",
        "for model_name, model in models_dict.items():\n",
        "    if model_name == \"ResNet18_Pretrained_224\":\n",
        "        test_loader = test_loader_224\n",
        "    else:\n",
        "        test_loader = test_loader_32\n",
        "\n",
        "    print(\"Model:\", model_name)\n",
        "    acc = evaluate_model(model, test_loader, device=device)\n",
        "    print(f\"{model_name}: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "y-RT-AJ-UkY4"
      },
      "outputs": [],
      "source": [
        "# Count trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "mxb49LSu5v4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7af109e-c4df-4d8f-a641-1645798bcac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trainable Parameters Per Model\n",
            "========================================\n",
            "SimpleCNN                      22,058\n",
            "ResNet18_Scratch_32            11,173,962\n",
            "ResNet18_Pretrained_224        11,181,642\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTrainable Parameters Per Model\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for name, model in models_dict.items():\n",
        "    params = count_parameters(model)\n",
        "    print(f\"{name:30s} {params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THZgmxHER6GF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}