<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Chapter 2: Data Preprocessing & Feature Engineering</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
  <style>
   body {
      font-family: 'Roboto', Arial, sans-serif;
      margin: 0;
      background: #17191a;
      min-height: 100vh;
      color: #ff79c6; /* MAIN PINK FONT COLOR */
      padding: 20px;
    }

    section {
      margin-bottom: 55px;
      background: #222025;
      border-radius: 18px;
      box-shadow: 0 4px 30px rgba(255,121,198,.09);
      padding: 36px 32px 22px 32px;
      transition: box-shadow .24s;
      border-left: 7px solid #ff79c6;
      position: relative;
      max-width: 850px;
      margin-left: auto;
      margin-right: auto;
    }

    section h4 {
      font-size: 1.18em;
      color: #ffb3de;
      margin-bottom: 5px;
      margin-top: 30px;
      font-weight: 600;
      border-bottom: 1px solid #ffb3de;
      padding-bottom: 2px;
    }

    pre {
      background: #19121a;
      color: #ffb3de;
      padding: 15px 18px;
      border-radius: 8px;
      font-size: 1.04em;
      line-height: 1.7;
      overflow-x: auto;
      box-shadow: 0 2px 10px rgba(255,121,198,0.11);
      position: relative;
    }

    pre .copy {
      position: absolute;
      top: 8px;
      right: 8px;
      padding: 4px 8px;
      background: #21111b;
      border: 1px solid #ff79c6;
      border-radius: 6px;
      color: #ffb3de;
      font-size: 0.8em;
      cursor: pointer;
    }
    pre .copy:hover {
      background: #ff79c6;
      color: #fff;
    }

    footer {
      margin-top: 46px;
      text-align: center;
      color: #ffb3de;
      font-size: 1.09em;
      letter-spacing: 1px;
      padding: 22px 0 14px 0;
      border-top: 1px solid #402138;
      background: none;
      font-weight: 500;
    }
  </style>
</head>
  
<body>

<section>
  <h4>One-Hot Encoding: Converts each category into binary columns</h4>
  <p>
    <strong>One-Hot Encoding</strong> is a technique used to convert categorical variables into a set of binary (0 or 1) columns.  
    Each unique category becomes a new column, and the row gets a <code>1</code> in the column for its category and <code>0</code> elsewhere.
  </p>
  <p>
    Example: If you have a feature <code>Color = ["Red", "Blue", "Green"]</code>:
  </p>
  <pre><code>
Red   → [1, 0, 0]
Blue  → [0, 1, 0]
Green → [0, 0, 1]
  </code></pre>
</section>

<section>
  <h4>Python Example: One-Hot Encoding with pandas</h4>
  <pre> <button class="copy">Copy</button> <code>
import pandas as pd

# Sample dataset
data = {'Color': ['Red', 'Blue', 'Green', 'Blue']}
df = pd.DataFrame(data)

print("Original Data:")
print(df)

# Apply one-hot encoding
encoded = pd.get_dummies(df, columns=['Color'])

print("\nAfter One-Hot Encoding:")
print(encoded)
  </code> </pre>
</section>

<section>
  <h4>Case Study: Titanic Dataset</h4>
  <pre> <button class="copy">Copy</button> <code>
      import pandas as pd
      from sklearn.datasets import fetch_openml
      from sklearn.model_selection import train_test_split
      from sklearn.linear_model import LogisticRegression
      from sklearn.metrics import accuracy_score
      
      # 1. Load Titanic dataset
      titanic = fetch_openml(name="titanic", version=1, as_frame=True, parser="auto")
      df = titanic.frame
      
      # 2. Select useful columns
      features = ["pclass", "sex", "age", "sibsp", "parch", "fare", "embarked"]
      df = df[features + ["survived"]].dropna()
      
      X = df[features]
      y = df["survived"].astype(int)
      
      # 3. One-Hot Encode categorical variables (sex, embarked)
      X_encoded = pd.get_dummies(X, columns=["sex", "embarked"], drop_first=True, dtype=int)
      # Dropping the first dummy column prevents the Dummy Variable Trap, 
      # where one category column can be perfectly predicted from the others, 
      # causing multicollinearity in linear models.
      
      print("Encoded Features (first 5 rows):")
      print(X_encoded.head())
      
      # 4. Train-test split
      X_train, X_test, y_train, y_test = train_test_split(
          X_encoded, y, test_size=0.2, random_state=42
      )
      
      # 5. Logistic Regression
      logreg = LogisticRegression(max_iter=2000)
      logreg.fit(X_train, y_train)
      y_pred = logreg.predict(X_test)
      
      # 6. Accuracy
      acc = accuracy_score(y_test, y_pred)
      print("\nAccuracy with pd.get_dummies + Logistic Regression:", acc)
  </code> </pre>
</section>
  
<section>
  <h4>Why Use One-Hot Encoding?</h4>
  <ul>
    <li>Avoids implying an order among categories (unlike label encoding).</li>
    <li>Makes categorical data usable in ML models that require numerical input.</li>
    <li>Works well for categorical variables with a small number of categories.</li>
  </ul>
</section>

<section>
  <h4>Limitations</h4>
  <ul>
    <li>Can create many new columns if there are lots of categories (high cardinality).</li>
    <li>Increases memory usage for large datasets.</li>
  </ul>
</section>
  
<script>
  document.querySelectorAll("pre .copy").forEach(button => {
    button.addEventListener("click", () => {
      const code = button.nextElementSibling.innerText;
      navigator.clipboard.writeText(code).then(() => {
        const old = button.textContent;
        button.textContent = "Copied!";
        setTimeout(() => button.textContent = old, 1500);
      });
    });
  });
</script>

</body>
</html>
