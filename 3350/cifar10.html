<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>CIFAR-10 Dataset & CNN Architecture Visualizer</title>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      background: linear-gradient(135deg, #1a1d1f 0%, #2a1e28 100%);
      font-family: 'Roboto', Arial, sans-serif;
      color: #ffb3de;
      min-height: 100vh;
      padding: 20px;
    }

    .container {
      max-width: 1600px;
      margin: 0 auto;
      background: #222025;
      border-radius: 18px;
      padding: 40px;
      box-shadow: 0 4px 30px rgba(255, 121, 198, 0.15);
      border-left: 7px solid #ff79c6;
    }

    h1 {
      color: #ff79c6;
      text-align: center;
      margin-bottom: 10px;
      font-size: 2.2em;
    }

    .subtitle {
      text-align: center;
      color: #ffb3de;
      margin-bottom: 20px;
      font-size: 1.1em;
    }

    .cifar-intro {
      background: #19121a;
      border-radius: 10px;
      padding: 18px 20px;
      margin-bottom: 25px;
      line-height: 1.7;
      font-size: 0.9em;
      border-left: 4px solid #50fa7b;
    }

    .cifar-intro strong {
      color: #fff52e;
    }

    /* CNN controls (simple info bar) */
    .controls {
      background: #2a1e28;
      border: 2px solid #ff79c6;
      border-radius: 12px;
      padding: 25px;
      margin-bottom: 30px;
      display: flex;
      gap: 25px;
      flex-wrap: wrap;
      align-items: center;
      justify-content: space-between;
    }

    .control-group {
      display: flex;
      flex-direction: column;
      gap: 6px;
    }

    .control-group label {
      color: #ff79c6;
      font-weight: 600;
      font-size: 0.95em;
    }

    .control-group span {
      font-size: 0.9em;
      color: #ffb3de;
    }

    button {
      background: linear-gradient(135deg, #ff79c6, #ffb3de);
      color: #1a1d1f;
      border: none;
      padding: 12px 30px;
      border-radius: 8px;
      font-weight: 600;
      cursor: pointer;
      font-size: 0.95em;
      transition: all 0.3s ease;
    }

    button:hover {
      transform: translateY(-2px);
      box-shadow: 0 6px 20px rgba(255, 121, 198, 0.4);
    }

    /* CNN pipeline styles */
    .pipeline-container {
      background: #2a1e28;
      border: 2px solid #ff79c6;
      border-radius: 12px;
      padding: 30px;
      margin-bottom: 30px;
    }

    .pipeline {
      display: flex;
      gap: 20px;
      overflow-x: auto;
      align-items: stretch;
      justify-content: space-between;
    }

    .stage {
      background: #19121a;
      border: 2px solid #50fa7b;
      border-radius: 12px;
      padding: 20px;
      flex: 1;
      min-width: 280px;
      text-align: center;
      transition: box-shadow 0.3s ease, border-color 0.3s ease;
    }

    .stage h3 {
      color: #ff79c6;
      margin-bottom: 10px;
      font-size: 1.1em;
    }

    .stage-op {
      font-size: 0.85em;
      color: #fff52e;
      margin-bottom: 8px;
      font-family: "Courier New", monospace;
    }

    .stage-info {
      color: #ffb3de;
      font-size: 0.9em;
      margin-bottom: 15px;
      line-height: 1.6;
    }

    .visualization {
      display: flex;
      justify-content: center;
      align-items: center;
      margin: 15px 0;
      min-height: 200px;
      background: #2a1e28;
      border-radius: 8px;
      padding: 10px;
    }

    canvas {
      border: 2px solid #ff79c6;
      border-radius: 8px;
    }

    .arrow {
      display: flex;
      align-items: center;
      justify-content: center;
      min-width: 40px;
      color: #50fa7b;
      font-size: 1.5em;
      font-weight: bold;
    }

    .legend {
      background: #2a1e28;
      border: 2px solid #ff79c6;
      border-radius: 12px;
      padding: 25px;
      margin-top: 20px;
    }

    .legend h3 {
      color: #ff79c6;
      margin-bottom: 20px;
      border-bottom: 2px solid #ff79c6;
      padding-bottom: 10px;
    }

    .legend-item {
      display: flex;
      align-items: center;
      gap: 15px;
      margin: 12px 0;
      color: #ffb3de;
    }

    .legend-color {
      width: 20px;
      height: 20px;
      border-radius: 50%;
      flex-shrink: 0;
    }

    .color-rgb { background: linear-gradient(135deg, #ff0000, #00ff00, #0000ff); }
    .color-conv { background: #50fa7b; }
    .color-pool { background: #ffb3de; }
    .color-output { background: #fff52e; }

    @media (max-width: 1200px) {
      .pipeline {
        flex-direction: column;
      }

      .arrow {
        transform: rotate(90deg);
      }
    }

    .param-info {
      background: #19121a;
      border-left: 4px solid #fff52e;
      padding: 15px;
      border-radius: 8px;
      color: #fff52e;
      font-family: 'Courier New', monospace;
      font-size: 0.85em;
      margin-top: 10px;
    }

    .credit {
      margin-top: 10px;
      font-size: 0.75em;
      color: #aaa;
    }

    .dataset-info {
      margin-top: 20px;
      background: #19121a;
      border-radius: 8px;
      padding: 15px;
      line-height: 1.6;
      font-size: 0.9em;
      border-left: 4px solid #ff79c6;
    }

    .dataset-info strong {
      color: #fff52e;
    }

    /* Conv demo panel */
    #conv-demo {
      background:#19121a;
      border:2px solid #ff79c6;
      padding:20px;
      border-radius:12px;
      color:#ffb3de;
      font-family:'Courier New', monospace;
      margin-top:20px;
      line-height:1.6;
    }

    @media (max-width: 768px) {
      .controls {
        flex-direction: column;
      }

      button {
        width: 100%;
      }
    }
  </style>
</head>
<body>

<div class="container">
  <h1>ðŸ§  CIFAR-10 Dataset & CNN Architecture</h1>
  <p class="subtitle">
    32Ã—32 RGB images (3 channels) â†’ Convolution + Pooling â†’ Fully Connected â†’ 10 CIFAR-10 Classes
  </p>

  <!-- CIFAR-10 introduction -->
  <div class="cifar-intro">
    <strong>What is CIFAR-10?</strong><br>
    CIFAR-10 is a classic benchmark dataset in computer vision. It contains
    <strong>60,000 small color images</strong> (32Ã—32 pixels with 3 RGB channels)
    divided into <strong>10 everyday object categories</strong> such as airplane,
    automobile, bird, cat, deer, dog, frog, horse, ship, and truck.
    In your PyTorch demo, you train a <strong>CNN model</strong> that takes a 32Ã—32Ã—3 image
    and predicts which of these 10 classes it belongs to.
  </div>

  <div class="controls">
    <div class="control-group">
      <label>CNN Input (for CIFAR-10)</label>
      <span>32 Ã— 32 Ã— 3 RGB image from CIFAR-10.</span>
      <span>Same shape as the dog image used below for visualization.</span>
    </div>
    <div class="control-group">
      <label>CNN Architecture (PyTorch Demo)</label>
      <span>Conv1 (5Ã—5, 16 filters) â†’ ReLU â†’ MaxPool (2Ã—2)</span>
      <span>Conv2 (5Ã—5, 32 filters) â†’ ReLU â†’ MaxPool (2Ã—2)</span>
      <span>Flatten â†’ Fully Connected â†’ Softmax (10 classes)</span>
    </div>
    <div class="control-group">
      <label>Big Picture</label>
      <span>This page explains <strong>how your PyTorch CNN processes CIFAR-10 images</strong>,</span>
      <span>and shows the same filter/patch idea using a real 32Ã—32 RGB dog photo.</span>
    </div>
  </div>

  <!-- CNN pipeline (adapted for CIFAR-10) -->
  <div class="pipeline-container">
    <div class="pipeline" id="pipeline"></div>
  </div>

  <div class="legend">
    <h3>ðŸ“Š CNN Components & Process (CIFAR-10-style CNN)</h3>
    <div class="legend-item">
      <div class="legend-color color-rgb"></div>
      <span><strong>Input Image:</strong> 32Ã—32 RGB (3 channels), here visualized with a real dog photo (same size as CIFAR-10 images).</span>
    </div>
    <div class="legend-item">
      <div class="legend-color color-conv"></div>
      <span><strong>Convolution + ReLU:</strong> Filters slide over the image to detect patterns (edges, textures, shapes); ReLU keeps only positive activations.</span>
    </div>
    <div class="legend-item">
      <div class="legend-color color-pool"></div>
      <span><strong>Pooling + ReLU:</strong> Max pooling shrinks the feature maps while keeping the strongest activations and making the model more robust.</span>
    </div>
    <div class="legend-item">
      <div class="legend-color color-output"></div>
      <span><strong>Output + Softmax:</strong> Flattened features go into fully connected layers; softmax turns scores into probabilities over the 10 CIFAR-10 classes.</span>
    </div>

    <h4 style="color: #ff79c6; margin-top: 25px; margin-bottom: 15px;">Conceptual Flow (Matches Your PyTorch CNN)</h4>
    <div style="background: #19121a; padding: 15px; border-radius: 8px; color: #ffb3de; line-height: 1.8;">
      <strong style="color: #50fa7b;">1. Input Layer:</strong> 32Ã—32Ã—3 RGB CIFAR-10 image.<br>
      <strong style="color: #50fa7b;">2. Conv Layer 1 + ReLU:</strong> 16 filters (5Ã—5) extract low-level edges and textures, then ReLU keeps positive responses.<br>
      <strong style="color: #50fa7b;">3. Pool Layer 1 + ReLU:</strong> 2Ã—2 max pooling downsamples to 14Ã—14 while keeping the strongest activations.<br>
      <strong style="color: #50fa7b;">4. Conv Layer 2 + ReLU:</strong> 32 filters (5Ã—5) build more complex shapes (eyes, noses, wheels, etc.).<br>
      <strong style="color: #50fa7b;">5. Pool Layer 2 + ReLU:</strong> Another 2Ã—2 max pooling â†’ compact 5Ã—5 feature maps (5Ã—5Ã—32 = 800 features).<br>
      <strong style="color: #50fa7b;">6. Output Layer + Softmax:</strong> Flattened features â†’ fully connected layer(s) â†’ softmax probabilities for 10 CIFAR-10 classes.
    </div>

    <div class="dataset-info">
      <strong>CIFAR-10 Dataset Summary:</strong><br>
      â€¢ 60,000 color images at 32Ã—32 resolution (50,000 train / 10,000 test).<br>
      â€¢ 3 channels per pixel (R, G, B) â‡’ 32 Ã— 32 Ã— 3 = 3,072 numbers per image.<br>
      â€¢ 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.<br>
      â€¢ This page visualizes the <strong>CNN model</strong> that you implement in PyTorch:
        convolution + pooling layers, then fully connected layers for 10-way classification.
    </div>
  </div>
</div>

<script>
// ====== Conv Demo: 32Ã—32Ã—3 + 5Ã—5Ã—3 â†’ 28Ã—28Ã—1 (with channels) ======
const CONV_DEMO_DOG_URL =
  "https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Labrador_Retriever_portrait.jpg/330px-Labrador_Retriever_portrait.jpg";

let convDemoImageData = null;   // 32Ã—32Ã—4 RGBA from downsampled dog
let convDemoOriginalImage = null;
let convDemoOutputRaw = null;   // 28Ã—28 raw conv (ReLU)
let convDemoOutputNorm = null;  // 28Ã—28 normalized to [0,255] for drawing
let convDemoWeights = null;     // 5Ã—5Ã—3 filter weights
let convDemoReady = false;

const CONV_DEMO_INPUT_SIZE = 32;
const CONV_DEMO_KERNEL = 5;
const CONV_DEMO_OUTPUT_SIZE = 28;

// Add a load handler (coexists with other onloads)
window.addEventListener('load', () => {
  convDemoInit();
});

function convDemoInit() {
  const img = new Image();
  img.crossOrigin = "Anonymous";
  img.src = CONV_DEMO_DOG_URL;

  img.onload = () => {
    convDemoOriginalImage = img;

    // Downsample to 32Ã—32
    const canvas32 = document.createElement('canvas');
    canvas32.width = CONV_DEMO_INPUT_SIZE;
    canvas32.height = CONV_DEMO_INPUT_SIZE;
    const ctx32 = canvas32.getContext('2d');
    ctx32.drawImage(img, 0, 0, CONV_DEMO_INPUT_SIZE, CONV_DEMO_INPUT_SIZE);

    try {
      convDemoImageData = ctx32.getImageData(0, 0, CONV_DEMO_INPUT_SIZE, CONV_DEMO_INPUT_SIZE);
    } catch (e) {
      console.error("Conv-demo getImageData failed:", e);
      const textDiv = document.getElementById('conv-demo-text');
      if (textDiv) {
        textDiv.textContent = "Failed to read pixel data from the dog image (browser security / CORS issue).";
      }
      return;
    }

    convDemoInitWeights();
    convDemoComputeConv();
    convDemoSetupControls();
    convDemoReady = true;
    convDemoRedraw();
  };

  img.onerror = () => {
    console.error("Conv demo: failed to load dog image");
    const textDiv = document.getElementById('conv-demo-text');
    if (textDiv) {
      textDiv.textContent = "Failed to load dog image from the internet.";
    }
  };
}

// Initialize one random 5Ã—5Ã—3 filter with small weights
function convDemoInitWeights() {
  const k = CONV_DEMO_KERNEL;
  convDemoWeights = new Float32Array(k * k * 3);
  for (let i = 0; i < convDemoWeights.length; i++) {
    convDemoWeights[i] = (Math.random() - 0.5) * 0.1; // ~[-0.05, 0.05]
  }
}

// Compute conv + ReLU for ONE filter over 32Ã—32Ã—3 â†’ 28Ã—28Ã—1
function convDemoComputeConv() {
  const outSize = CONV_DEMO_OUTPUT_SIZE;
  const inSize = CONV_DEMO_INPUT_SIZE;
  const k = CONV_DEMO_KERNEL;
  const data = convDemoImageData.data;

  convDemoOutputRaw = new Float32Array(outSize * outSize);

  let maxVal = 0;

  for (let oy = 0; oy < outSize; oy++) {
    for (let ox = 0; ox < outSize; ox++) {
      let sum = 0;
      for (let ky = 0; ky < k; ky++) {
        for (let kx = 0; kx < k; kx++) {
          const iy = oy + ky;
          const ix = ox + kx;
          const baseIndex = (iy * inSize + ix) * 4;  // RGBA
          const r = data[baseIndex];
          const g = data[baseIndex + 1];
          const b = data[baseIndex + 2];

          const wIndexBase = (ky * k + kx) * 3;
          const wr = convDemoWeights[wIndexBase];
          const wg = convDemoWeights[wIndexBase + 1];
          const wb = convDemoWeights[wIndexBase + 2];

          sum += r * wr + g * wg + b * wb;
        }
      }
      // bias = 0; ReLU
      sum = Math.max(0, sum);
      const idx = oy * outSize + ox;
      convDemoOutputRaw[idx] = sum;
      if (sum > maxVal) maxVal = sum;
    }
  }

  // Normalize to [0,255] for drawing
  if (maxVal <= 0) maxVal = 1;
  convDemoOutputNorm = new Uint8ClampedArray(outSize * outSize);
  for (let i = 0; i < convDemoOutputRaw.length; i++) {
    convDemoOutputNorm[i] = Math.min(255, Math.round(convDemoOutputRaw[i] / maxVal * 255));
  }
}

function convDemoSetupControls() {
  const ySlider = document.getElementById('conv-demo-y');
  const xSlider = document.getElementById('conv-demo-x');
  const yVal = document.getElementById('conv-demo-y-value');
  const xVal = document.getElementById('conv-demo-x-value');

  if (!ySlider || !xSlider || !yVal || !xVal) return;

  const handler = () => {
    yVal.textContent = ySlider.value;
    xVal.textContent = xSlider.value;
    convDemoRedraw();
  };

  ySlider.addEventListener('input', handler);
  xSlider.addEventListener('input', handler);

  yVal.textContent = ySlider.value;
  xVal.textContent = xSlider.value;
}

function convDemoRedraw() {
  if (!convDemoReady || !convDemoImageData) return;

  const ySlider = document.getElementById('conv-demo-y');
  const xSlider = document.getElementById('conv-demo-x');
  const oy = ySlider ? parseInt(ySlider.value, 10) : 0;
  const ox = xSlider ? parseInt(xSlider.value, 10) : 0;

  convDemoDrawInputCanvas(oy, ox);
  convDemoDrawOutputCanvas(oy, ox);
  convDemoDrawChannelPatchesAndFilters(oy, ox);
  convDemoUpdateText(oy, ox);
}

// ---- 1) Big input canvas: highlight 5Ã—5 patch ----
function convDemoDrawInputCanvas(oy, ox) {
  const canvas = document.getElementById('conv-demo-input-canvas');
  if (!canvas) return;
  const ctx = canvas.getContext('2d');

  const size = CONV_DEMO_INPUT_SIZE; // 32
  const scale = canvas.width / size; // ~9.3 px per pixel

  // Draw the 32Ã—32 input, upscaled
  const imgCanvas = document.createElement('canvas');
  imgCanvas.width = size;
  imgCanvas.height = size;
  const imgCtx = imgCanvas.getContext('2d');
  imgCtx.putImageData(convDemoImageData, 0, 0);

  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.imageSmoothingEnabled = false;
  ctx.drawImage(imgCanvas, 0, 0, canvas.width, canvas.height);

  // Highlight 5Ã—5 patch starting at (ox, oy)
  const k = CONV_DEMO_KERNEL; // 5
  ctx.strokeStyle = '#fff52e';
  ctx.lineWidth = 3;
  ctx.strokeRect(ox * scale, oy * scale, k * scale, k * scale);
}

// ---- 2) Big output canvas: 28Ã—28 feature map ----
function convDemoDrawOutputCanvas(oy, ox) {
  const canvas = document.getElementById('conv-demo-output-canvas');
  if (!canvas || !convDemoOutputNorm) return;
  const ctx = canvas.getContext('2d');

  const outSize = CONV_DEMO_OUTPUT_SIZE; // 28
  const scale = canvas.width / outSize;  // 10 px per pixel

  ctx.clearRect(0, 0, canvas.width, canvas.height);

  for (let y = 0; y < outSize; y++) {
    for (let x = 0; x < outSize; x++) {
      const v = convDemoOutputNorm[y * outSize + x];
      ctx.fillStyle = `rgb(${v},${v},${v})`;
      ctx.fillRect(x * scale, y * scale, scale, scale);
    }
  }

  // Highlight selected output pixel
  ctx.strokeStyle = '#50fa7b';
  ctx.lineWidth = 3;
  ctx.strokeRect(ox * scale, oy * scale, scale, scale);
}

// ---- 3) Channel patches & filter weights (5Ã—5 each) ----
function convDemoDrawChannelPatchesAndFilters(oy, ox) {
  const patchCanvases = [
    document.getElementById('conv-demo-patch-R'),
    document.getElementById('conv-demo-patch-G'),
    document.getElementById('conv-demo-patch-B')
  ];
  const filterCanvases = [
    document.getElementById('conv-demo-filter-R'),
    document.getElementById('conv-demo-filter-G'),
    document.getElementById('conv-demo-filter-B')
  ];
  if (!patchCanvases[0] || !filterCanvases[0] || !convDemoImageData || !convDemoWeights) return;

  const inSize = CONV_DEMO_INPUT_SIZE;
  const k = CONV_DEMO_KERNEL;
  const data = convDemoImageData.data;

  // Draw 5Ã—5 patches from each channel
  for (let c = 0; c < 3; c++) {
    const pCanvas = patchCanvases[c];
    const pCtx = pCanvas.getContext('2d');
    const cellSize = pCanvas.width / k;

    pCtx.clearRect(0, 0, pCanvas.width, pCanvas.height);

    for (let py = 0; py < k; py++) {
      for (let px = 0; px < k; px++) {
        const iy = oy + py;
        const ix = ox + px;
        const baseIndex = (iy * inSize + ix) * 4;
        const v = data[baseIndex + c];  // channel value (0â€“255)

        let r = 0, g = 0, b = 0;
        if (c === 0) r = v;
        if (c === 1) g = v;
        if (c === 2) b = v;

        pCtx.fillStyle = `rgb(${r},${g},${b})`;
        pCtx.fillRect(px * cellSize, py * cellSize, cellSize, cellSize);
      }
    }
  }

  // Draw 5Ã—5 filter weights for each channel (simple grayscale heatmap)
  for (let c = 0; c < 3; c++) {
    const fCanvas = filterCanvases[c];
    const fCtx = fCanvas.getContext('2d');
    const cellSize = fCanvas.width / k;

    // Find min and max for this channel to normalize
    let minW = Infinity;
    let maxW = -Infinity;
    for (let ky = 0; ky < k; ky++) {
      for (let kx = 0; kx < k; kx++) {
        const wIndexBase = (ky * k + kx) * 3 + c;
        const w = convDemoWeights[wIndexBase];
        if (w < minW) minW = w;
        if (w > maxW) maxW = w;
      }
    }
    if (minW === maxW) {
      minW -= 0.001;
      maxW += 0.001;
    }

    fCtx.clearRect(0, 0, fCanvas.width, fCanvas.height);
    for (let ky = 0; ky < k; ky++) {
      for (let kx = 0; kx < k; kx++) {
        const wIndexBase = (ky * k + kx) * 3 + c;
        const w = convDemoWeights[wIndexBase];
        const t = (w - minW) / (maxW - minW); // 0..1
        const v = Math.round(t * 255);
        fCtx.fillStyle = `rgb(${v},${v},${v})`;
        fCtx.fillRect(kx * cellSize, ky * cellSize, cellSize, cellSize);
      }
    }
  }
}

// ---- 4) Numeric explanation: sum_R, sum_G, sum_B, ReLU ----
function convDemoUpdateText(oy, ox) {
  const textDiv = document.getElementById('conv-demo-text');
  if (!textDiv || !convDemoOutputRaw || !convDemoImageData || !convDemoWeights) return;

  const outSize = CONV_DEMO_OUTPUT_SIZE;
  const inSize = CONV_DEMO_INPUT_SIZE;
  const k = CONV_DEMO_KERNEL;
  const data = convDemoImageData.data;

  // Index into output map
  const outIdx = oy * outSize + ox;
  const rawVal = convDemoOutputRaw[outIdx];
  const normVal = convDemoOutputNorm[outIdx];

  // Recompute separate sums for R, G, B for this patch
  let sumR = 0, sumG = 0, sumB = 0;

  for (let ky = 0; ky < k; ky++) {
    for (let kx = 0; kx < k; kx++) {
      const iy = oy + ky;
      const ix = ox + kx;
      const baseIndex = (iy * inSize + ix) * 4;

      const r = data[baseIndex];
      const g = data[baseIndex + 1];
      const b = data[baseIndex + 2];

      const wIndex = (ky * k + kx) * 3;
      const wr = convDemoWeights[wIndex];
      const wg = convDemoWeights[wIndex + 1];
      const wb = convDemoWeights[wIndex + 2];

      sumR += r * wr;
      sumG += g * wg;
      sumB += b * wb;
    }
  }

  const total = sumR + sumG + sumB;
  const relu = Math.max(0, total);

  textDiv.innerHTML =
    `At output position (y, x) = (<span style="color:#fff52e;">${oy}</span>, ` +
    `<span style="color:#fff52e;">${ox}</span>):<br>` +
    `&nbsp;&nbsp;â€¢ We take a <span style="color:#50fa7b;">5Ã—5Ã—3</span> patch starting at (y, x) = (${oy}, ${ox}).<br>` +
    `&nbsp;&nbsp;â€¢ For each channel, we multiply the 5Ã—5 patch by the 5Ã—5 filter weights and sum them:<br>` +
    `&nbsp;&nbsp;&nbsp;&nbsp;R channel sum = <span style="color:#ff79c6;">${sumR.toFixed(2)}</span><br>` +
    `&nbsp;&nbsp;&nbsp;&nbsp;G channel sum = <span style="color:#ff79c6;">${sumG.toFixed(2)}</span><br>` +
    `&nbsp;&nbsp;&nbsp;&nbsp;B channel sum = <span style="color:#ff79c6;">${sumB.toFixed(2)}</span><br>` +
    `&nbsp;&nbsp;â€¢ Add them together (bias = 0 here):<br>` +
    `&nbsp;&nbsp;&nbsp;&nbsp;total = R + G + B = <span style="color:#50fa7b;">${total.toFixed(2)}</span><br>` +
    `&nbsp;&nbsp;â€¢ Apply ReLU: max(0, total) = <span style="color:#50fa7b;">${relu.toFixed(2)}</span><br>` +
    `&nbsp;&nbsp;â†’ This value becomes the single pixel in the <span style="color:#fff52e;">28Ã—28</span> feature map ` +
    `at (y, x) = (${oy}, ${ox}).<br>` +
    `&nbsp;&nbsp;â†’ In the feature map canvas, this is drawn with grayscale intensity ` +
    `<span style="color:#ff79c6;">${normVal}</span> (0â€“255).`;
}
</script>

<script>
// ====== CNN Pipeline (adapted from your CNN visualizer, but described for CIFAR-10) ======
const stages = [
  {
    name: 'Input Image',
    op: 'RGB + Channels',
    size: '32Ã—32Ã—3',
    info: 'A 32Ã—32 color image (same size as a CIFAR-10 image). Below we show the full RGB and each channel separately.',
    process: 'drawInputImage'
  },
  {
    name: 'Conv Layer 1',
    op: 'Conv (5Ã—5, 16 filters) + ReLU',
    size: '28Ã—28Ã—16',
    info: '16 different 5Ã—5 filters slide over the image to detect simple edges and textures. ReLU sets negative responses to 0.',
    process: 'drawConv1'
  },
  {
    name: 'Pool Layer 1',
    op: 'Max Pool (2Ã—2) + ReLU',
    size: '14Ã—14Ã—16',
    info: '2Ã—2 max pooling shrinks each feature map by taking the strongest activation in each 2Ã—2 region.',
    process: 'drawPool1'
  },
  {
    name: 'Conv Layer 2',
    op: 'Conv (5Ã—5, 32 filters) + ReLU',
    size: '10Ã—10Ã—32',
    info: '32 filters now look at the pooled maps to detect more complex patterns (object parts: heads, legs, wheels, etc.).',
    process: 'drawConv2'
  },
  {
    name: 'Pool Layer 2',
    op: 'Max Pool (2Ã—2) + ReLU',
    size: '5Ã—5Ã—32',
    info: 'Another max pooling step compresses the information into a compact but rich set of feature maps.',
    process: 'drawPool2'
  },
  {
    name: 'Output Layer',
    op: 'Fully Connected + Softmax',
    size: '10 classes (CIFAR-10)',
    info: 'Flattened features go into a fully connected layer. Softmax converts scores into probabilities for the 10 CIFAR-10 classes.',
    process: 'drawSoftmax'
  }
];

let imageData = null;
let originalDogImage = null;

// URL of a public-domain dog image from Wikimedia Commons
const DOG_IMAGE_URL =
  "https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Labrador_Retriever_portrait.jpg/330px-Labrador_Retriever_portrait.jpg";

function loadDogImage(callback) {
  const img = new Image();
  img.crossOrigin = "Anonymous";
  img.src = DOG_IMAGE_URL;

  img.onload = () => {
    originalDogImage = img;

    // Downsample to 32Ã—32 for the CNN "input"
    const canvas32 = document.createElement('canvas');
    canvas32.width = 32;
    canvas32.height = 32;
    const ctx32 = canvas32.getContext('2d');
    ctx32.drawImage(img, 0, 0, 32, 32);
    try {
      imageData = ctx32.getImageData(0, 0, 32, 32);
    } catch (e) {
      console.error("getImageData failed, falling back to null imageData:", e);
      imageData = null;
    }

    callback();
  };

  img.onerror = () => {
    console.error("Failed to load dog image from internet.");
    imageData = null;
    callback();
  };
}

function renderPipeline() {
  const pipeline = document.getElementById('pipeline');
  pipeline.innerHTML = '';

  stages.forEach((stage, index) => {
    const stageDiv = document.createElement('div');
    stageDiv.className = 'stage';
    stageDiv.innerHTML = `
      <h3>${stage.name}</h3>
      <div class="stage-op">${stage.op}</div>
      <div class="stage-info">${stage.info}</div>
      <div class="visualization" id="vis-${index}"></div>
      <div class="param-info">${stage.size}</div>
    `;
    pipeline.appendChild(stageDiv);

    if (index < stages.length - 1) {
      const arrow = document.createElement('div');
      arrow.className = 'arrow';
      arrow.textContent = 'â†’';
      pipeline.appendChild(arrow);
    }
  });

  renderVisualizations();
}

function renderVisualizations() {
  stages.forEach((stage, index) => {
    const container = document.getElementById(`vis-${index}`);
    if (typeof window[stage.process] === 'function') {
      window[stage.process](container);
    }
  });
}

// ---- draw RGB + three channels ----
function drawInputImage(container) {
  container.innerHTML = '';

  const wrapper = document.createElement('div');
  wrapper.style.display = 'flex';
  wrapper.style.flexDirection = 'column';
  wrapper.style.alignItems = 'center';
  wrapper.style.gap = '10px';

  // 1) Top: original dog photo
  const colorCanvas = document.createElement('canvas');
  colorCanvas.width = 160;
  colorCanvas.height = 120;
  const colorCtx = colorCanvas.getContext('2d');

  if (originalDogImage) {
    const aspect = originalDogImage.width / originalDogImage.height;
    let drawW = 160;
    let drawH = drawW / aspect;
    if (drawH > 120) {
      drawH = 120;
      drawW = drawH * aspect;
    }
    const offsetX = (160 - drawW) / 2;
    const offsetY = (120 - drawH) / 2;
    colorCtx.drawImage(originalDogImage, offsetX, offsetY, drawW, drawH);
  } else if (imageData) {
    const imgCanvas = document.createElement('canvas');
    imgCanvas.width = 32;
    imgCanvas.height = 32;
    const imgCtx = imgCanvas.getContext('2d');
    imgCtx.putImageData(imageData, 0, 0);
    colorCtx.imageSmoothingEnabled = false;
    colorCtx.drawImage(imgCanvas, 0, 0, 160, 120);
  } else {
    colorCtx.fillStyle = '#50fa7b';
    colorCtx.fillRect(0, 0, 160, 120);
  }

  const colorLabel = document.createElement('div');
  colorLabel.textContent = 'RGB image (downsampled input, same size as CIFAR-10)';
  colorLabel.style.fontSize = '0.8em';
  colorLabel.style.marginTop = '4px';

  const colorBlock = document.createElement('div');
  colorBlock.style.display = 'flex';
  colorBlock.style.flexDirection = 'column';
  colorBlock.style.alignItems = 'center';
  colorBlock.appendChild(colorCanvas);
  colorBlock.appendChild(colorLabel);

  wrapper.appendChild(colorBlock);

  // 2) Bottom row: R, G, B channels (from 32Ã—32Ã—3)
  if (imageData) {
    const channelsRow = document.createElement('div');
    channelsRow.style.display = 'flex';
    channelsRow.style.gap = '10px';
    channelsRow.style.marginTop = '6px';
    channelsRow.style.flexWrap = 'wrap';
    channelsRow.style.justifyContent = 'center';

    const channelNames = ['R', 'G', 'B'];
    const channelColorFns = [
      v => `rgb(${v},0,0)`,   // Red
      v => `rgb(0,${v},0)`,   // Green
      v => `rgb(0,0,${v})`    // Blue
    ];

    for (let c = 0; c < 3; c++) {
      const chCanvas = document.createElement('canvas');
      chCanvas.width = 96;  // 32 * 3
      chCanvas.height = 96;
      const chCtx = chCanvas.getContext('2d');

      const scale = 3;
      const w = 32;
      const h = 32;

      for (let y = 0; y < h; y++) {
        for (let x = 0; x < w; x++) {
          const idx = (y * w + x) * 4;
          const v = imageData.data[idx + c]; // channel value
          chCtx.fillStyle = channelColorFns[c](v);
          chCtx.fillRect(x * scale, y * scale, scale, scale);
        }
      }

      const chLabel = document.createElement('div');
      chLabel.textContent = `${channelNames[c]} channel`;
      chLabel.style.fontSize = '0.8em';
      chLabel.style.marginTop = '4px';

      const chBlock = document.createElement('div');
      chBlock.style.display = 'flex';
      chBlock.style.flexDirection = 'column';
      chBlock.style.alignItems = 'center';

      chBlock.appendChild(chCanvas);
      chBlock.appendChild(chLabel);
      channelsRow.appendChild(chBlock);
    }

    wrapper.appendChild(channelsRow);
  }

  container.appendChild(wrapper);
}

// Lightweight helpers reused from your CNN visualizer
function applySimpleEdgeDetection(imgData, w, h, outSize) {
  const edges = new Array(outSize * outSize).fill(0);

  for (let y = 0; y < outSize; y++) {
    for (let x = 0; x < outSize; x++) {
      let sum = 0;
      let count = 0;
      for (let dy = 0; dy < 5; dy++) {
        for (let dx = 0; dx < 5; dx++) {
          const iy = y + dy;
          const ix = x + dx;
          if (iy < h && ix < w) {
            const idx = (iy * w + ix) * 4;
            const r = imgData.data[idx];
            const g = imgData.data[idx + 1];
            const b = imgData.data[idx + 2];
            sum += (r + g + b) / 3;
            count++;
          }
        }
      }
      const avg = sum / Math.max(count, 1);
      let activation = avg - 100;
      activation = Math.max(0, activation); // ReLU
      edges[y * outSize + x] = Math.min(activation * 2, 255);
    }
  }

  return edges;
}

function applyMaxPooling(data, w, h, poolSize) {
  const outW = Math.floor(w / poolSize);
  const outH = Math.floor(h / poolSize);
  const pooled = new Array(outW * outH).fill(0);

  for (let y = 0; y < outH; y++) {
    for (let x = 0; x < outW; x++) {
      let max = 0;
      for (let py = 0; py < poolSize; py++) {
        for (let px = 0; px < poolSize; px++) {
          const iy = y * poolSize + py;
          const ix = x * poolSize + px;
          if (iy < h && ix < w) {
            const idx = iy * w + ix;
            max = Math.max(max, data[idx]);
          }
        }
      }
      pooled[y * outW + x] = Math.max(0, max);
    }
  }

  return pooled;
}

function drawConv1(container) {
  const canvas = document.createElement('canvas');
  canvas.width = 120;
  canvas.height = 120;
  const ctx = canvas.getContext('2d');

  ctx.fillStyle = '#2a1e28';
  ctx.fillRect(0, 0, 120, 120);

  if (imageData) {
    const edges = applySimpleEdgeDetection(imageData, 32, 32, 28);
    const scaleFactor = 120 / 28;

    edges.forEach((pixel, idx) => {
      const x = Math.floor((idx % 28) * scaleFactor);
      const y = Math.floor(Math.floor(idx / 28) * scaleFactor);
      ctx.fillStyle = `rgb(${pixel},${pixel},${pixel})`;
      ctx.fillRect(x, y, scaleFactor, scaleFactor);
    });
  }

  container.appendChild(canvas);
}

function drawPool1(container) {
  const canvas = document.createElement('canvas');
  canvas.width = 120;
  canvas.height = 120;
  const ctx = canvas.getContext('2d');

  ctx.fillStyle = '#2a1e28';
  ctx.fillRect(0, 0, 120, 120);

  if (imageData) {
    const edges = applySimpleEdgeDetection(imageData, 32, 32, 28);
    const pooled = applyMaxPooling(edges, 28, 28, 2);
    const scaleFactor = 120 / 14;

    pooled.forEach((pixel, idx) => {
      const x = Math.floor((idx % 14) * scaleFactor);
      const y = Math.floor(Math.floor(idx / 14) * scaleFactor);
      ctx.fillStyle = `rgb(${pixel},${pixel},${pixel})`;
      ctx.fillRect(x, y, scaleFactor, scaleFactor);
    });
  }

  container.appendChild(canvas);
}

function drawConv2(container) {
  const canvas = document.createElement('canvas');
  canvas.width = 120;
  canvas.height = 120;
  const ctx = canvas.getContext('2d');

  ctx.fillStyle = '#2a1e28';
  ctx.fillRect(0, 0, 120, 120);

  if (imageData) {
    const edges = applySimpleEdgeDetection(imageData, 32, 32, 28);
    const pooled = applyMaxPooling(edges, 28, 28, 2); // 14Ã—14

    const expanded = Array.from({ length: pooled.length * 4 }, (_, i) => pooled[Math.floor(i / 4)]);
    const fakeImgData = {
      data: expanded.flatMap(v => [v, v, v, 255])
    };
    const conv2 = applySimpleEdgeDetection(fakeImgData, 14, 14, 10);
    const scaleFactor = 120 / 10;

    conv2.slice(0, 100).forEach((pixel, idx) => {
      const x = Math.floor((idx % 10) * scaleFactor);
      const y = Math.floor(Math.floor(idx / 10) * scaleFactor);
      ctx.fillStyle = `rgb(${Math.min(pixel + 40, 255)},${Math.min(pixel + 10, 255)},${pixel})`;
      ctx.fillRect(x, y, scaleFactor, scaleFactor);
    });
  }

  container.appendChild(canvas);
}

function drawPool2(container) {
  const canvas = document.createElement('canvas');
  canvas.width = 120;
  canvas.height = 120;
  const ctx = canvas.getContext('2d');

  ctx.fillStyle = '#2a1e28';
  ctx.fillRect(0, 0, 120, 120);

  const scaleFactor = 120 / 5;
  for (let i = 0; i < 5; i++) {
    for (let j = 0; j < 5; j++) {
      const brightness = Math.floor(Math.random() * 100) + 100;
      ctx.fillStyle = `rgb(${brightness},${brightness + 50},${brightness})`;
      ctx.fillRect(i * scaleFactor, j * scaleFactor, scaleFactor, scaleFactor);
    }
  }

  container.appendChild(canvas);
}

function drawSoftmax(container) {
  const canvas = document.createElement('canvas');
  canvas.width = 260;
  canvas.height = 160;
  const ctx = canvas.getContext('2d');

  ctx.fillStyle = '#19121a';
  ctx.fillRect(0, 0, canvas.width, canvas.height);

  // Show 4 sample CIFAR-10 classes + "others"
  const labels = ['Cat', 'Dog', 'Airplane', 'Truck', 'Others'];
  const probs = [0.35, 0.25, 0.10, 0.05, 0.25];
  const barWidth = 30;
  const baseX = 30;
  const baseY = 120;
  const maxBarHeight = 80;

  ctx.font = '11px Roboto, Arial';
  ctx.textAlign = 'center';

  for (let i = 0; i < labels.length; i++) {
    const barHeight = probs[i] * maxBarHeight;
    const x = baseX + i * 45;
    const y = baseY - barHeight;

    ctx.fillStyle =
      i === 0 ? '#ff79c6' :
      i === 1 ? '#50fa7b' :
      i === 2 ? '#fff52e' :
      i === 3 ? '#8be9fd' :
      '#bd93f9';

    ctx.fillRect(x, y, barWidth, barHeight);

    ctx.fillStyle = '#ffffff';
    ctx.fillText((probs[i] * 100).toFixed(0) + '%', x + barWidth / 2, y - 4);
    ctx.fillText(labels[i], x + barWidth / 2, baseY + 15);
  }

  ctx.strokeStyle = '#ffffff';
  ctx.beginPath();
  ctx.moveTo(20, baseY);
  ctx.lineTo(canvas.width - 10, baseY);
  ctx.stroke();

  const caption = document.createElement('div');
  caption.style.fontSize = '0.8em';
  caption.style.marginTop = '6px';
  caption.style.color = '#ffb3de';
  caption.textContent = 'Softmax outputs probabilities over the 10 CIFAR-10 classes (only a few are shown here).';

  container.appendChild(canvas);
  container.appendChild(caption);
}

// Initialize CNN pipeline after image loads
window.addEventListener('load', () => {
  loadDogImage(() => {
    renderPipeline();
  });
});
</script>

</body>
</html>
