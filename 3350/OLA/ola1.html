<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>OLA1 – Data Preprocessing & Feature Engineering</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      max-width: 950px;
      margin: 0 auto;
      padding: 20px;
      background-color: #17191a;
      color: #ff79c6;
    }
    .container {
      background-color: #222025;
      padding: 30px;
      border-radius: 8px;
      box-shadow: 0 2px 12px rgba(255,121,198,0.15);
    }
    h1 {
      text-align: center;
      font-size: 26px;
      color: #ff79c6;
      margin-bottom: 6px;
    }
    h2.course-title {
      text-align: center;
      font-size: 28px;
      color: #ffb3de;
      margin-bottom: 18px;
    }
    h3.deadline {
      text-align: center;
      font-size: 15px;
      color: #ffb3de;
      margin-top: 0;
      margin-bottom: 20px;
    }
    h3 {
      color: #ff79c6;
      font-size: 22px;
      margin-bottom: 12px;
      border-bottom: 3px solid #ff79c6;
      padding-bottom: 6px;
    }
    h4 {
      color: #ffb3de;
      font-size: 18px;
      margin-top: 20px;
      margin-bottom: 8px;
      border-bottom: 1px solid #ffb3de;
      padding-bottom: 3px;
    }
    pre {
      background: #19121a;
      color: #ffb3de;
      padding: 15px;
      border-radius: 6px;
      font-size: 0.95em;
      overflow-x: auto;
    }
    code {
      font-family: Consolas, monospace;
    }
    table {
      width: 70%;
      margin: 15px auto;
      border-collapse: collapse;
      font-size: 0.9em;
      color: #ffb3de;
    }
    th, td {
      border: 1px solid #ff79c6;
      padding: 6px 10px;
      text-align: left;
    }
    th {
      background: #19121a;
      color: #ff79c6;
    }
    tr:nth-child(even) {
      background: #2b2b2b;
    }
    #backToTop {
      position: fixed;
      bottom: 24px;
      right: 24px;
      background-color: #ff79c6;
      color: #fff;
      border: none;
      border-radius: 50%;
      width: 48px;
      height: 48px;
      font-size: 1.3em;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      box-shadow: 0 4px 12px rgba(0,0,0,0.25);
      transition: background 0.2s;
    }
    #backToTop:hover {
      background-color: #ffb3de;
      color: #17191a;
    }
    footer {
      text-align: center;
      margin-top: 30px;
      font-size: 0.9em;
      color: #ffb3de;
    }
  </style>
</head>
<body>

<div class="container">
  <h2 class="course-title">CSCI 3350 -- Machine Learning</h2>
  <h1>OLA1 – Data Preprocessing & Feature Engineering</h1>
  <h3 class="deadline"><font color="red">Deadline:</font> September 14th, 2025 (Sunday)</h3>

  <h3>Objective</h3>
  <p>
    The purpose of this assignment is to practice <b>data preprocessing</b> using a real dataset. 
    Data preprocessing includes <b>data cleaning, data transformation, feature engineering, 
    feature selection, and dimensionality reduction</b>.  
    You will apply these techniques on the built-in <b>Wine Dataset</b> from scikit-learn. 
  </p>

  <h3>Steps to Complete</h3>
  <ol>
    <li><b>Load and Inspect the Dataset</b>  
      – Load using <code>load_wine(as_frame=True)</code>, print shape, and show the first 5 rows.</li>
    <li><b>Data Cleaning</b>  
      – Check for missing values and duplicates. Report if any issues exist and how you fixed them.</li>
    
       <li><b>Feature Engineering</b>  
      – Create <code>phenols_ratio = flavanoids / total_phenols</code>. Explain why this may matter.</li>
    
    <li><b>Data Transformation</b>  
      – Standardize features with <code>StandardScaler</code>. Explain why scaling is necessary.</li>
 
    <li><b>Feature Selection</b>  
      – Use <code>chi2</code> (with discretization) and <code>RFE</code> with Logistic Regression.  
      – Compare accuracy using all features vs selected features.</li>
    <li><b>Dimensionality Reduction with PCA</b>  
      – Reduce features to 2 components and plot results with colors for wine classes.  
      – Report explained variance ratio.</li>
    <li><b>Discussion</b>  
      – Reflect on which features were most important, and whether feature selection improved performance.</li>
  </ol>

  <h3>Starter Code</h3>
  <pre><code>
# --- Please import necessary libraries here ---
from sklearn.datasets import load_wine

# --- 1. Load dataset ---
wine = load_wine(as_frame=True)
data = wine.frame   # full DataFrame (features + target)

# --- 2. Data Cleaning ---
#  (check missing values and duplicates)
#

# --- 3. Split the cleaned data into X and y ---  
X = data_clean.drop(columns=["target"])
y = data_clean["target"]
    
# --- 4. Feature Engineering ---
# Create new feature: phenols_ratio

# --- 5. Train/test split --- 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
    
# --- 6. Baseline Logistic Regression  --- 
# --- Baseline Logistic Regression ---
baseline = LogisticRegression(max_iter=5000, solver="liblinear")
baseline.fit(X_train, y_train)
y_pred = baseline.predict(X_test)
print("Baseline Accuracy (all features):", accuracy_score(y_test, y_pred))

# --- 7. Logistic Regression with Standardization ---
# Make sure standardization only fits to training data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # fit on train only
X_test_scaled  = scaler.transform(X_test)
# 
# finish your code here
#    
print("Scaled Accuracy (all features):", accuracy_score(y_test, y_pred_scale))
    
# --- 8. Logistic Regression with Feature Selection: Chi-square test ---
# For the chi-square test, please don't apply standardization
# (1) Discretize (fit only on train, transform test)
discretizer = KBinsDiscretizer(n_bins=5, encode="ordinal", strategy="uniform")
X_train_binned = discretizer.fit_transform(X_train)
X_test_binned  = discretizer.transform(X_test)

# (2) SelectKBest with chi2 as the scoring function
selector = SelectKBest(score_func=chi2, k=10)
X_train_sel = selector.fit_transform(X_train_binned, y_train)   # fit on train
X_test_sel  = selector.transform(X_test_binned)   

# 
# finish your code here
# 
print("Chi2 Accuracy (top 10 features):", accuracy_score(y_test, y_pred_chi))

    
# --- 9. Logistic Regression with Feature Selection: RFE (select top 5 features) ---
# For RFE, you can apply standardization first, make sure it only fits to training data

# 
# finish your code here
# 
print("RFE Accuracy (top 10 features):", accuracy_score(y_test, y_pred_rfe))
    
# --- 10. PCA (2D visualization) ---
# Please make sure to fit only on the scaled training data

# --- 11. PCA (3D visualization) ---
from mpl_toolkits.mplot3d import Axes3D  # 3D projection

# PCA with 3 components
pca = PCA(n_components=3)
X_pca = pca.fit_transform(X_train_scaled)

print("Explained Variance Ratio:", pca.explained_variance_ratio_)

# Put into a DataFrame
df_pca = pd.DataFrame(X_pca, columns=["PC1", "PC2", "PC3"])
df_pca["target"] = y_train.values  # use training labels

# Plot 3D PCA
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

colors = ["red", "green", "blue"]

for target, color, label in zip([0, 1, 2], colors, wine.target_names):
    subset = df_pca[df_pca["target"] == target]
    ax.scatter(subset["PC1"], subset["PC2"], subset["PC3"],
               color=color, alpha=0.7, label=label)

ax.set_xlabel("Principal Component 1")
ax.set_ylabel("Principal Component 2")
ax.set_zlabel("Principal Component 3")
ax.set_title("3D PCA of Wine Dataset (3 Components)")
ax.legend()
plt.show()

    
# --- 13. Discussion ---
# 
  </code></pre>

  <h3>Submission</h3>
  <p>
    Submit your Jupyter Notebook file <code>ola1.ipynb</code> 
    with all outputs and plots in D2L. 
    Include short explanations for each step. 
  </p>

  <h3>Grading Distribution (Total: 100 points)</h3>
  <table>
    <tr><th>Task</th><th>Points</th></tr>
    <tr><td>Load & Inspect Dataset</td><td>5</td></tr>
    <tr><td>Data Cleaning</td><td>10</td></tr>
    <tr><td>Data Transformation</td><td>15</td></tr>
    <tr><td>Feature Engineering</td><td>10</td></tr>
    <tr><td>Feature Selection</td><td>20</td></tr>
    <tr><td>Dimensionality Reduction (PCA)</td><td>20</td></tr>
    <tr><td>Discussion & Analysis</td><td>10</td></tr>
    <tr><td>Code Style, Clarity, and Explanations</td><td>10</td></tr>
    <tr><th>Total</th><th>100</th></tr>
  </table>

  <footer>
    Copy Right @ Dr. Xin Yang <br>
    Department Of Computer Science <br>
    Middle Tennessee State University
  </footer>
</div>

<!-- Back-to-top button -->
<button id="backToTop" title="Go to top">↑</button>

<script>
  // Back-to-top button functionality
  document.getElementById("backToTop").addEventListener("click", () => {
    window.scrollTo({ top: 0, behavior: "smooth" });
  });
</script>

</body>
</html>
