import React, { useState, useEffect } from 'react';
import { ChevronLeft, ChevronRight, Play, BarChart3, Split, Shuffle, Target, AlertTriangle, CheckCircle, Code, BookOpen, Users } from 'lucide-react';

const MLEvaluationTutorial = () => {
  const [currentSlide, setCurrentSlide] = useState(0);
  const [showCode, setShowCode] = useState(false);

  const slides = [
    // Slide 1: Title
    {
      id: 'title',
      title: 'Machine Learning Evaluation & Validation',
      content: (
        <div className="text-center py-12">
          <div className="mb-8">
            <BarChart3 className="w-24 h-24 mx-auto text-blue-500 mb-4" />
            <h1 className="text-4xl font-bold text-gray-800 mb-4">
              ML Evaluation & Validation
            </h1>
            <p className="text-xl text-gray-600 max-w-2xl mx-auto">
              Learn the fundamental concepts of proper model evaluation, validation strategies, 
              and how to avoid common pitfalls in machine learning
            </p>
          </div>
          <div className="grid grid-cols-3 gap-6 max-w-4xl mx-auto mt-12">
            <div className="bg-blue-50 p-6 rounded-lg border border-blue-200">
              <Target className="w-12 h-12 text-blue-500 mx-auto mb-3" />
              <h3 className="font-semibold text-blue-800">Evaluation</h3>
              <p className="text-sm text-blue-600">Measure true performance</p>
            </div>
            <div className="bg-green-50 p-6 rounded-lg border border-green-200">
              <Split className="w-12 h-12 text-green-500 mx-auto mb-3" />
              <h3 className="font-semibold text-green-800">Validation</h3>
              <p className="text-sm text-green-600">Choose best models</p>
            </div>
            <div className="bg-purple-50 p-6 rounded-lg border border-purple-200">
              <Shuffle className="w-12 h-12 text-purple-500 mx-auto mb-3" />
              <h3 className="font-semibold text-purple-800">Cross-Validation</h3>
              <p className="text-sm text-purple-600">Robust estimation</p>
            </div>
          </div>
        </div>
      )
    },
    
    // Slide 2: Why Evaluation Matters
    {
      id: 'why-evaluation',
      title: '1. Why Evaluation & Validation?',
      content: (
        <div className="space-y-8">
          <div className="bg-red-50 border-l-4 border-red-400 p-6 rounded-r-lg">
            <div className="flex items-center mb-4">
              <AlertTriangle className="w-6 h-6 text-red-500 mr-2" />
              <h3 className="text-lg font-semibold text-red-800">The Problem</h3>
            </div>
            <p className="text-red-700 mb-4">
              <strong>Training accuracy alone can be misleading!</strong>
            </p>
            <div className="bg-white p-4 rounded border">
              <code className="text-sm">
                model.fit(X_train, y_train)<br/>
                train_score = model.score(X_train, y_train)  # 99% accuracy!<br/>
                test_score = model.score(X_test, y_test)     # 65% accuracy üòû
              </code>
            </div>
          </div>

          <div className="grid grid-cols-1 md:grid-cols-3 gap-6">
            <div className="bg-blue-50 p-6 rounded-lg border border-blue-200">
              <Target className="w-8 h-8 text-blue-500 mb-3" />
              <h4 className="font-semibold text-blue-800 mb-2">Evaluation</h4>
              <p className="text-blue-700 text-sm">
                Estimate how well your model will perform on <strong>unseen data</strong> (generalization)
              </p>
            </div>
            <div className="bg-green-50 p-6 rounded-lg border border-green-200">
              <CheckCircle className="w-8 h-8 text-green-500 mb-3" />
              <h4 className="font-semibold text-green-800 mb-2">Validation</h4>
              <p className="text-green-700 text-sm">
                Choose best models and hyperparameters <strong>without test leakage</strong>
              </p>
            </div>
            <div className="bg-purple-50 p-6 rounded-lg border border-purple-200">
              <BarChart3 className="w-8 h-8 text-purple-500 mb-3" />
              <h4 className="font-semibold text-purple-800 mb-2">Optimization</h4>
              <p className="text-purple-700 text-sm">
                Actually minimize the <strong>right objective</strong> for your problem
              </p>
            </div>
          </div>

          <div className="bg-yellow-50 border border-yellow-200 p-4 rounded-lg">
            <p className="text-yellow-800">
              <strong>Key Insight:</strong> We need to simulate how our model performs on "future" data we haven't seen yet.
            </p>
          </div>
        </div>
      )
    },

    // Slide 3: Train-Test-Validation Split
    {
      id: 'train-test-split',
      title: '2. Train‚ÄìTest‚ÄìValidation Splits',
      content: (
        <div className="space-y-8">
          <div className="bg-gradient-to-r from-blue-50 to-green-50 p-6 rounded-lg">
            <h3 className="text-xl font-semibold mb-4 text-gray-800">The Three-Way Split</h3>
            <div className="grid grid-cols-3 gap-4 mb-6">
              <div className="bg-blue-100 p-4 rounded border-2 border-blue-300">
                <h4 className="font-semibold text-blue-800">Training Set (60-70%)</h4>
                <p className="text-sm text-blue-700">Learn patterns & fit model</p>
              </div>
              <div className="bg-yellow-100 p-4 rounded border-2 border-yellow-300">
                <h4 className="font-semibold text-yellow-800">Validation Set (15-20%)</h4>
                <p className="text-sm text-yellow-700">Tune hyperparameters</p>
              </div>
              <div className="bg-green-100 p-4 rounded border-2 border-green-300">
                <h4 className="font-semibold text-green-800">Test Set (15-20%)</h4>
                <p className="text-sm text-green-700">Final evaluation</p>
              </div>
            </div>
            
            <div className="bg-white p-4 rounded border">
              <div className="flex items-center mb-2">
                <Code className="w-4 h-4 mr-2" />
                <span className="font-semibold">Implementation</span>
              </div>
              <pre className="text-sm text-gray-800 overflow-x-auto">
{`from sklearn.model_selection import train_test_split

# First split: 80% train+val / 20% test
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Second split: 60% train / 20% val (from the 80%)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)`}
              </pre>
            </div>
          </div>

          <div className="bg-red-50 border-l-4 border-red-400 p-4 rounded-r-lg">
            <div className="flex items-center mb-2">
              <AlertTriangle className="w-5 h-5 text-red-500 mr-2" />
              <strong className="text-red-800">Golden Rule</strong>
            </div>
            <p className="text-red-700">
              Keep the test set <strong>completely untouched</strong> until the very end! 
              Only use it once for final evaluation.
            </p>
          </div>
        </div>
      )
    },

    // Slide 4: Data Leakage
    {
      id: 'data-leakage',
      title: '2.2 Data Leakage - The Silent Killer',
      content: (
        <div className="space-y-6">
          <div className="bg-red-100 border border-red-300 p-6 rounded-lg">
            <div className="flex items-center mb-4">
              <AlertTriangle className="w-6 h-6 text-red-600 mr-2" />
              <h3 className="text-xl font-semibold text-red-800">What is Data Leakage?</h3>
            </div>
            <p className="text-red-700 mb-4">
              When information from the future (validation/test sets) accidentally "leaks" into your training process, 
              leading to <strong>overly optimistic performance estimates</strong>.
            </p>
          </div>

          <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
            <div className="bg-red-50 p-6 rounded-lg border border-red-200">
              <h4 className="font-semibold text-red-800 mb-3 flex items-center">
                <span className="text-red-600 mr-2">‚ùå</span> Wrong Way
              </h4>
              <pre className="text-sm text-red-700 bg-red-100 p-3 rounded">
{`# LEAKAGE! Scaling on full data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Then split
X_train, X_test = train_test_split(X_scaled, ...)`}
              </pre>
              <p className="text-sm text-red-600 mt-2">
                The scaler "sees" test data during fit()!
              </p>
            </div>

            <div className="bg-green-50 p-6 rounded-lg border border-green-200">
              <h4 className="font-semibold text-green-800 mb-3 flex items-center">
                <span className="text-green-600 mr-2">‚úÖ</span> Correct Way
              </h4>
              <pre className="text-sm text-green-700 bg-green-100 p-3 rounded">
{`# Split first
X_train, X_test = train_test_split(X, ...)

# Scale only on training data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)`}
              </pre>
              <p className="text-sm text-green-600 mt-2">
                Scaler only learns from training data!
              </p>
            </div>
          </div>

          <div className="bg-blue-50 p-6 rounded-lg border border-blue-200">
            <h4 className="font-semibold text-blue-800 mb-3">Pipeline Solution</h4>
            <pre className="text-sm text-blue-700 bg-blue-100 p-4 rounded">
{`from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

# Pipeline prevents leakage automatically
pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("classifier", LogisticRegression(max_iter=1000))
])

pipe.fit(X_train, y_train)  # Scaler only sees training data`}
            </pre>
          </div>

          <div className="bg-yellow-50 border border-yellow-200 p-4 rounded-lg">
            <p className="text-yellow-800">
              <strong>Remember:</strong> Any preprocessing step (scaling, encoding, feature selection) 
              should only "see" the training fold during cross-validation!
            </p>
          </div>
        </div>
      )
    },

    // Slide 5: Cross-Validation Introduction
    {
      id: 'cv-intro',
      title: '3. Cross-Validation',
      content: (
        <div className="space-y-8">
          <div className="bg-gradient-to-r from-purple-50 to-blue-50 p-6 rounded-lg">
            <div className="flex items-center mb-4">
              <Shuffle className="w-8 h-8 text-purple-500 mr-3" />
              <h3 className="text-2xl font-semibold text-gray-800">Why Cross-Validation?</h3>
            </div>
            <p className="text-gray-700 text-lg mb-4">
              A single train/validation split might be <strong>unlucky</strong>. 
              CV gives us multiple "chances" to evaluate our model more reliably.
            </p>
          </div>

          <div className="grid grid-cols-1 md:grid-cols-2 gap-8">
            <div className="space-y-4">
              <h4 className="text-xl font-semibold text-gray-800">Single Split Problems</h4>
              <div className="bg-red-50 p-4 rounded-lg border border-red-200">
                <ul className="space-y-2 text-red-700">
                  <li>‚Ä¢ Validation set might be "too easy" or "too hard"</li>
                  <li>‚Ä¢ Results depend on random split</li>
                  <li>‚Ä¢ Wastes data (validation set sits unused)</li>
                  <li>‚Ä¢ High variance in performance estimates</li>
                </ul>
              </div>
            </div>

            <div className="space-y-4">
              <h4 className="text-xl font-semibold text-gray-800">Cross-Validation Benefits</h4>
              <div className="bg-green-50 p-4 rounded-lg border border-green-200">
                <ul className="space-y-2 text-green-700">
                  <li>‚Ä¢ Every sample gets to be in validation once</li>
                  <li>‚Ä¢ More robust performance estimates</li>
                  <li>‚Ä¢ Better use of available data</li>
                  <li>‚Ä¢ Can compute confidence intervals</li>
                </ul>
              </div>
            </div>
          </div>

          <div className="bg-blue-50 p-6 rounded-lg border border-blue-200">
            <h4 className="font-semibold text-blue-800 mb-3">The Cross-Validation Process</h4>
            <div className="grid grid-cols-5 gap-2 mb-4">
              {[1,2,3,4,5].map(fold => (
                <div key={fold} className="text-center">
                  <div className="bg-blue-200 p-2 rounded mb-1 text-sm font-semibold">
                    Fold {fold}
                  </div>
                  <div className={`p-1 rounded text-xs ${fold === 1 ? 'bg-yellow-200 text-yellow-800' : 'bg-green-200 text-green-800'}`}>
                    {fold === 1 ? 'Validation' : 'Training'}
                  </div>
                </div>
              ))}
            </div>
            <p className="text-blue-700 text-sm">
              Each fold serves as validation once, training four times. Final score = average of all folds.
            </p>
          </div>
        </div>
      )
    },

    // Slide 6: K-Fold Cross-Validation
    {
      id: 'k-fold',
      title: '3.1 K-Fold Cross-Validation',
      content: (
        <div className="space-y-6">
          <div className="bg-blue-50 p-6 rounded-lg">
            <h3 className="text-xl font-semibold text-blue-800 mb-4">How K-Fold Works</h3>
            <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
              <div>
                <h4 className="font-semibold mb-2">Algorithm:</h4>
                <ol className="list-decimal list-inside space-y-2 text-blue-700">
                  <li>Split data into <strong>k</strong> equal folds</li>
                  <li>For each fold i = 1 to k:</li>
                  <li className="ml-4">‚Ä¢ Use fold i as validation</li>
                  <li className="ml-4">‚Ä¢ Use other k-1 folds as training</li>
                  <li className="ml-4">‚Ä¢ Train model and compute score</li>
                  <li>Average all k scores</li>
                </ol>
              </div>
              <div>
                <h4 className="font-semibold mb-2">Visual Representation:</h4>
                <div className="space-y-2">
                  {[1,2,3,4,5].map(fold => (
                    <div key={fold} className="flex">
                      <span className="text-xs w-12">Fold {fold}:</span>
                      <div className="flex-1 flex">
                        {[1,2,3,4,5].map(segment => (
                          <div 
                            key={segment} 
                            className={`flex-1 h-6 border border-gray-300 ${
                              segment === fold ? 'bg-yellow-300' : 'bg-green-300'
                            }`}
                          />
                        ))}
                      </div>
                    </div>
                  ))}
                </div>
                <div className="text-xs mt-2">
                  <span className="inline-block w-4 h-4 bg-green-300 border mr-2"></span>Training
                  <span className="inline-block w-4 h-4 bg-yellow-300 border mr-2 ml-4"></span>Validation
                </div>
              </div>
            </div>
          </div>

          <div className="bg-gray-50 p-6 rounded-lg">
            <div className="flex items-center mb-3">
              <Code className="w-5 h-5 mr-2" />
              <h4 className="font-semibold">Implementation</h4>
            </div>
            <pre className="text-sm bg-gray-100 p-4 rounded overflow-x-auto">
{`from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LogisticRegression

# Create 5-fold CV
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Model
model = LogisticRegression(max_iter=1000)

# Perform cross-validation
scores = cross_val_score(model, X, y, cv=cv, scoring="accuracy")

print(f"CV Scores: {scores}")
print(f"Mean CV Score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")

# Output example:
# CV Scores: [0.85 0.88 0.82 0.87 0.86]
# Mean CV Score: 0.856 (+/- 0.048)`}
            </pre>
          </div>

          <div className="grid grid-cols-2 gap-4">
            <div className="bg-green-50 p-4 rounded-lg border border-green-200">
              <h4 className="font-semibold text-green-800 mb-2">Typical k values:</h4>
              <ul className="text-sm text-green-700 space-y-1">
                <li>‚Ä¢ <strong>k=5:</strong> Good balance, most common</li>
                <li>‚Ä¢ <strong>k=10:</strong> More robust, slower</li>
                <li>‚Ä¢ <strong>k=n:</strong> LOOCV (next slide)</li>
              </ul>
            </div>
            <div className="bg-yellow-50 p-4 rounded-lg border border-yellow-200">
              <h4 className="font-semibold text-yellow-800 mb-2">Trade-offs:</h4>
              <ul className="text-sm text-yellow-700 space-y-1">
                <li>‚Ä¢ <strong>Higher k:</strong> Less bias, more variance</li>
                <li>‚Ä¢ <strong>Lower k:</strong> More bias, less variance</li>
                <li>‚Ä¢ <strong>Computation:</strong> k times slower</li>
              </ul>
            </div>
          </div>
        </div>
      )
    },

    // Slide 7: LOOCV and Stratified K-Fold
    {
      id: 'advanced-cv',
      title: '3.2 Leave-One-Out & Stratified K-Fold',
      content: (
        <div className="space-y-8">
          <div className="grid grid-cols-1 md:grid-cols-2 gap-8">
            {/* LOOCV */}
            <div className="bg-purple-50 p-6 rounded-lg border border-purple-200">
              <h3 className="text-xl font-semibold text-purple-800 mb-4">Leave-One-Out CV (LOOCV)</h3>
              <p className="text-purple-700 mb-4">
                Extreme case where k = n (number of samples). Each sample is validation once.
              </p>
              
              <div className="bg-purple-100 p-4 rounded mb-4">
                <h4 className="font-semibold text-purple-800 mb-2">Characteristics:</h4>
                <ul className="text-sm text-purple-700 space-y-1">
                  <li>‚Ä¢ <strong>Very low bias</strong> (almost all data for training)</li>
                  <li>‚Ä¢ <strong>High variance</strong> (training sets are very similar)</li>
                  <li>‚Ä¢ <strong>Computationally expensive</strong> (n models to train)</li>
                  <li>‚Ä¢ <strong>Deterministic</strong> (no randomness in splits)</li>
                </ul>
              </div>

              <pre className="text-sm bg-purple-100 p-3 rounded">
{`from sklearn.model_selection import LeaveOneOut

loo = LeaveOneOut()
scores = cross_val_score(model, X, y, cv=loo)
print(f"LOOCV Score: {scores.mean():.3f}")`}
              </pre>
            </div>

            {/* Stratified K-Fold */}
            <div className="bg-green-50 p-6 rounded-lg border border-green-200">
              <h3 className="text-xl font-semibold text-green-800 mb-4">Stratified K-Fold</h3>
              <p className="text-green-700 mb-4">
                Maintains the <strong>same class distribution</strong> in each fold. Essential for imbalanced datasets!
              </p>
              
              <div className="bg-green-100 p-4 rounded mb-4">
                <h4 className="font-semibold text-green-800 mb-2">Why Stratify?</h4>
                <div className="text-sm text-green-700 space-y-2">
                  <div>Original: 90% Class A, 10% Class B</div>
                  <div>‚Ä¢ Regular K-Fold: Some folds might have 0% Class B!</div>
                  <div>‚Ä¢ Stratified: Each fold has ~90% A, ~10% B</div>
                </div>
              </div>

              <pre className="text-sm bg-green-100 p-3 rounded">
{`from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=skf, scoring="f1_macro")
print(f"Stratified CV: {scores.mean():.3f}")`}
              </pre>
            </div>
          </div>

          <div className="bg-blue-50 p-6 rounded-lg border border-blue-200">
            <h3 className="text-xl font-semibold text-blue-800 mb-4">Comparison Summary</h3>
            <div className="overflow-x-auto">
              <table className="w-full text-sm">
                <thead>
                  <tr className="bg-blue-100">
                    <th className="p-3 text-left">Method</th>
                    <th className="p-3 text-left">When to Use</th>
                    <th className="p-3 text-left">Pros</th>
                    <th className="p-3 text-left">Cons</th>
                  </tr>
                </thead>
                <tbody className="text-blue-700">
                  <tr className="border-b border-blue-200">
                    <td className="p-3 font-semibold">K-Fold (k=5)</td>
                    <td className="p-3">General purpose, balanced datasets</td>
                    <td className="p-3">Fast, good bias-variance trade-off</td>
                    <td className="p-3">May not preserve class distribution</td>
                  </tr>
                  <tr className="border-b border-blue-200">
                    <td className="p-3 font-semibold">Stratified K-Fold</td>
                    <td className="p-3">Classification, imbalanced data</td>
                    <td className="p-3">Maintains class ratios</td>
                    <td className="p-3">Only for classification</td>
                  </tr>
                  <tr>
                    <td className="p-3 font-semibold">LOOCV</td>
                    <td className="p-3">Small datasets, need low bias</td>
                    <td className="p-3">Maximum use of data</td>
                    <td className="p-3">Very slow, high variance</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
      )
    },

    // Slide 8: Hands-on Example
    {
      id: 'hands-on',
      title: 'Hands-On Example: Putting It All Together',
      content: (
        <div className="space-y-6">
          <div className="bg-gradient-to-r from-blue-50 to-purple-50 p-6 rounded-lg">
            <h3 className="text-xl font-semibold mb-4 text-gray-800">Complete Workflow Example</h3>
            <p className="text-gray-700 mb-4">
              Let's implement a proper ML pipeline with evaluation, avoiding data leakage!
            </p>
          </div>

          <div className="bg-gray-50 p-6 rounded-lg">
            <pre className="text-sm text-gray-800 overflow-x-auto">
{`import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix

# 1. LOAD DATA
# Assume we have X (features) and y (labels)

# 2. TRAIN/TEST SPLIT (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 3. CREATE PIPELINE (prevents leakage!)
pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression(max_iter=1000))
])

# 4. HYPERPARAMETER TUNING with CV
param_grid = {
    'classifier__C': [0.01, 0.1, 1, 10, 100],
    'classifier__penalty': ['l1', 'l2', 'elasticnet']
}

# Use stratified CV for grid search
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
grid_search = GridSearchCV(
    pipe, param_grid, cv=cv, scoring='f1_macro', n_jobs=-1
)

# Fit on training data only
grid_search.fit(X_train, y_train)

print(f"Best parameters: {grid_search.best_params_}")
print(f"Best CV score: {grid_search.best_score_:.3f}")

# 5. FINAL EVALUATION (on test set - only once!)
best_model = grid_search.best_estimator_
test_score = best_model.score(X_test, y_test)
y_pred = best_model.predict(X_test)

print(f"\\nFinal test accuracy: {test_score:.3f}")
print("\\nClassification Report:")
print(classification_report(y_test, y_pred))`}
            </pre>
          </div>

          <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
            <div className="bg-green-50 p-4 rounded-lg border border-green-200">
              <h4 className="font-semibold text-green-800 mb-3">‚úÖ What We Did Right</h4>
              <ul className="text-sm text-green-700 space-y-2">
                <li>‚Ä¢ Split data before any preprocessing</li>
                <li>‚Ä¢ Used Pipeline to prevent leakage</li>
                <li>‚Ä¢ Stratified CV for hyperparameter tuning</li>
                <li>‚Ä¢ Only touched test set once at the end</li>
                <li>‚Ä¢ Proper evaluation metrics</li>
              </ul>
            </div>

            <div className="bg-blue-50 p-4 rounded-lg border border-blue-200">
              <h4 className="font-semibold text-blue-800 mb-3">üìä Key Takeaways</h4>
              <ul className="text-sm text-blue-700
