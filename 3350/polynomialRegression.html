<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Worked Example: Linear vs Polynomial Regression (Synthetic Quadratic)</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
  <style>
   body {
      font-family: 'Roboto', Arial, sans-serif;
      margin: 0;
      background: #17191a;
      min-height: 100vh;
      color: #ff79c6;
      padding: 20px;
    }

    section {
      margin-bottom: 55px;
      background: #222025;
      border-radius: 18px;
      box-shadow: 0 4px 30px rgba(255,121,198,.09);
      padding: 36px 32px 22px 32px;
      transition: box-shadow .24s;
      border-left: 7px solid #ff79c6;
      position: relative;
      max-width: 950px;
      margin-left: auto;
      margin-right: auto;
    }

    h1, h2, h4 {
      margin: 0 0 10px 0;
      color: #ffb3de;
      font-weight: 700;
    }

    section h4 {
      font-size: 1.18em;
      color: #ffb3de;
      margin-bottom: 5px;
      margin-top: 30px;
      font-weight: 600;
      border-bottom: 1px solid #ffb3de;
      padding-bottom: 2px;
    }

    a.anchor {
      text-decoration: none;
      margin-left: .5rem;
      opacity: .6;
      color: #ffb3de;
    }
    a.anchor:hover { opacity: 1; }

    pre {
      background: #19121a;
      color: #ffb3de;
      padding: 15px 18px;
      border-radius: 8px;
      font-size: 1.04em;
      line-height: 1.7;
      overflow-x: auto;
      box-shadow: 0 2px 10px rgba(255,121,198,0.11);
      position: relative;
      max-width: 100%;
    }

    pre .copy {
      position: absolute;
      top: 8px;
      right: 8px;
      padding: 4px 8px;
      background: #21111b;
      border: 1px solid #ff79c6;
      border-radius: 6px;
      color: #ffb3de;
      font-size: 0.8em;
      cursor: pointer;
    }
    pre .copy:hover {
      background: #ff79c6;
      color: #fff;
    }

    ul.toc {
      padding-left: 18px;
      margin-top: 8px;
    }
    ul.toc li { margin: 4px 0; }
    ul.toc a { color: #ffb3de; }
  </style>
</head>

<body>

<section>
  <center>
    <h1>Worked Example: Linear vs Polynomial Regression</h1>
    <div>Synthetic Quadratic Data</div>
  </center>

  <h4>Method: Linear vs Polynomial (d=2, d=8) </h4>

  <pre><button class="copy">Copy</button><code>
# ========================================================
# Synthetic Quadratic Data — Linear vs Polynomial Regression
# Train/test split, compare models, show metrics
# ========================================================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import r2_score, mean_squared_error

RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)
pd.set_option("display.float_format", "{:.4f}".format)
    
# 1) Generate synthetic quadratic dataset
# X is evenly spaced between –3 and 3 (80 points)
X = np.linspace(-3, 3, 80).reshape(-1, 1)

# y_true= 0.5x^2+x+2 --> this is the real curve (a parabola)
y_true = 0.5 * X**2 + X + 2    # true quadratic curve

#We add random noise so it looks like messy, real-world data
y = y_true + np.random.randn(len(X)) * 1.5 # add noise

X_matrix = X.reshape(-1, 1)
    
# 2) Train / test split
X_train, X_test, y_train, y_test = train_test_split(
    X_matrix, y, test_size=0.3, random_state=RANDOM_STATE
)

# 3) Helper function to evaluate models
def evaluate_model(name, model, X_train, y_train, X_test, y_test):
    
    model.fit(X_train, y_train)

    # --- Train ---
    y_pred_train = model.predict(X_train)
    mse_train = mean_squared_error(y_train, y_pred_train)
    rmse_train = np.sqrt(mse_train)
    r2_train = r2_score(y_train, y_pred_train)
    sse_train = np.sum((y_train - y_pred_train) ** 2)

    # --- Test ---
    y_pred_test = model.predict(X_test)
    mse_test = mean_squared_error(y_test, y_pred_test)
    rmse_test = np.sqrt(mse_test)
    r2_test = r2_score(y_test, y_pred_test)
    sse_test = np.sum((y_test - y_pred_test) ** 2)

    # Put results in DataFrame
    results = pd.DataFrame([
        {"Model": name, "Split": "Train", "R^2": r2_train, "RMSE": rmse_train, "MSE": mse_train, "SSE": sse_train},
        {"Model": name, "Split": "Test",  "R^2": r2_test,  "RMSE": rmse_test,  "MSE": mse_test,  "SSE": sse_test},
    ])
    return results

# 4) Define models

lin_reg  = Pipeline([
    ("scaler", StandardScaler()),
    ("linre", LinearRegression())
])

poly2 = Pipeline([
    ("scaler", StandardScaler()),
    # creates features x, x^2
    ("poly", PolynomialFeatures(degree=2, include_bias=False)),
    ("linreg", LinearRegression())
])

poly8 = Pipeline([
    ("scaler", StandardScaler()),
    # creates features x, x^2, x^3, x^4, x^5, x^6, x^7, x^8
    ("poly", PolynomialFeatures(degree=8, include_bias=False)),
    ("linreg", LinearRegression())
])

# 5) Evaluate models
results_df = pd.concat([
        evaluate_model("Linear Regression", lin_reg, X_train, y_train, X_test, y_test),
        evaluate_model("Polynomial d=2", poly2, X_train, y_train, X_test, y_test),
        evaluate_model("Polynomial d=8", poly8, X_train, y_train, X_test, y_test),
    ]).set_index(["Model", "Split"])

# 6) Display results
print(results_df)

# 7) Plot fitted curves
X_curve = np.linspace(-3, 3, 200).reshape(-1, 1)
    
plt.scatter(X, y, color="black", label="Data (with noise)")
plt.plot(X_matrix, y_true, "g--", label="True function")

plt.plot(X_curve, lin_reg.fit(X_train, y_train).predict(X_curve), "r-", label="Linear Regression")
plt.plot(X_curve, poly2.fit(X_train, y_train).predict(X_curve), "b-", label="Polynomial d=2")
plt.plot(X_curve, poly8.fit(X_train, y_train).predict(X_curve), "m-", label="Polynomial d=8")

plt.legend()
plt.title("Linear vs Polynomial Regression (Train/Test split)")
plt.xlabel("X")
plt.ylabel("y")
plt.show()
  </code></pre>

<h3>What Pipeline means</h3>
In scikit-learn, a Pipeline is a way to chain multiple preprocessing steps and a model into a single object.
It guarantees that:
  
<UL>
  <LI>The steps are applied in order.</LI>
  <LI>When you call .fit(X, y), each step transforms the data and passes it along.</LI>
  <LI>When you call .predict(X), the same transformations happen automatically.</LI>
</UL>
  
</section>

<script>
  document.querySelectorAll("pre .copy").forEach(button => {
    button.addEventListener("click", () => {
      const code = button.nextElementSibling.innerText;
      navigator.clipboard.writeText(code).then(() => {
        const old = button.textContent;
        button.textContent = "Copied!";
        setTimeout(() => button.textContent = old, 1500);
      });
    });
  });
</script>

</body>
</html>
