<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Artificial Neural Networks</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <style>
    body {
      margin: 0;
      padding: 20px;
      background: #17191a;
      font-family: 'Roboto', Arial, sans-serif;
      color: #ff79c6;
      min-height: 100vh;
    }

    .container {
      max-width: 1400px;
      margin: 0 auto;
      background: #222025;
      border-radius: 18px;
      padding: 40px;
      box-shadow: 0 4px 30px rgba(255,121,198,.09);
      border-left: 7px solid #ff79c6;
    }

    h1 {
      color: #ff79c6;
      text-align: center;
      font-size: 2.5em;
      margin-bottom: 10px;
      text-shadow: 0 2px 16px rgba(255,121,198,.18);
    }

    .subtitle {
      color: #ffb3de;
      text-align: center;
      font-size: 1.1em;
      margin-bottom: 40px;
    }

    .taxonomy {
      background: #19121a;
      border-radius: 12px;
      padding: 30px;
      margin-bottom: 40px;
      border: 2px solid #ff79c6;
      overflow-x: auto;
    }

    .tree-line {
      color: #50fa7b;
      font-family: 'Courier New', monospace;
      font-size: 1em;
      line-height: 1.8;
      white-space: pre;
      margin: 0;
    }

    .categories {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 25px;
      margin-top: 40px;
    }

    .category-box {
      background: #2a1e28;
      border: 2px solid #ff79c6;
      border-radius: 12px;
      padding: 25px;
      transition: transform 0.3s, box-shadow 0.3s;
    }

    .category-box:hover {
      transform: translateY(-5px);
      box-shadow: 0 8px 20px rgba(255,121,198,0.2);
    }

    .category-title {
      color: #ff79c6;
      font-size: 1.4em;
      font-weight: 700;
      margin: 0 0 15px 0;
      border-bottom: 2px solid #ffb3de;
      padding-bottom: 10px;
      display: flex;
      align-items: center;
      gap: 10px;
    }

    .icon {
      font-size: 1.5em;
    }

    .subcategory {
      background: #19121a;
      padding: 12px;
      margin: 10px 0;
      border-left: 4px solid #50fa7b;
      border-radius: 6px;
      color: #ffb3de;
    }

    .subcategory-title {
      color: #fff52e;
      font-weight: 600;
      display: flex;
      align-items: center;
      gap: 8px;
    }

    .subcategory-desc {
      color: #ffb3de;
      font-size: 0.9em;
      margin-top: 6px;
      margin-left: 20px;
    }

    .description {
      margin-top: 8px;
      padding-top: 8px;
      border-top: 1px solid #ffb3de;
      color: #ffb3de;
      font-size: 0.95em;
      line-height: 1.5;
    }

    .features {
      margin-top: 10px;
      padding-left: 20px;
    }

    .features li {
      color: #ffb3de;
      margin: 5px 0;
      font-size: 0.9em;
    }

    .legend {
      background: #2a1e28;
      border: 2px solid #ff79c6;
      border-radius: 12px;
      padding: 20px;
      margin-top: 40px;
    }

    .legend h3 {
      color: #ff79c6;
      margin-top: 0;
    }

    .legend-item {
      display: flex;
      align-items: center;
      gap: 15px;
      margin: 12px 0;
      color: #ffb3de;
    }

    .legend-color {
      width: 25px;
      height: 25px;
      border-radius: 4px;
      flex-shrink: 0;
    }

    .color-feedforward { background: #ff79c6; }
    .color-recurrent { background: #50fa7b; }
    .color-generative { background: #fff52e; }
    .color-graph { background: #8be9fd; }
    .color-attention { background: #ff85b3; }
  </style>
</head>
<body>

<div class="container">
  <h1>ğŸ§  Artificial Neural Networks</h1>
  <p class="subtitle">Complete classification of ANN architectures and their applications</p>

  <div class="taxonomy">
    <pre class="tree-line">Artificial Neural Networks (ANN)
â”‚
â”œâ”€â”€ Feedforward Networks
â”‚   â”œâ”€â”€ Perceptron
â”‚   â”œâ”€â”€ MLP (Multi-Layer Perceptron)
â”‚   â”œâ”€â”€ DNN (Deep Neural Network)
â”‚   â””â”€â”€ CNN (Convolutional Neural Network)
â”‚
â”œâ”€â”€ Recurrent Networks
â”‚   â”œâ”€â”€ RNN (Recurrent Neural Network)
â”‚   â”œâ”€â”€ LSTM (Long Short-Term Memory)
â”‚   â”œâ”€â”€ GRU (Gated Recurrent Unit)
â”‚
â”œâ”€â”€ Generative Networks
â”‚   â”œâ”€â”€ Autoencoder
â”‚   â”œâ”€â”€ VAE (Variational Autoencoder)
â”‚   â”œâ”€â”€ GAN (Generative Adversarial Network)
â”‚
â”œâ”€â”€ Graph-Based Networks
â”‚   â”œâ”€â”€ GNN (Graph Neural Network)
â”‚   â”œâ”€â”€ GCN (Graph Convolutional Network)
â”‚
â””â”€â”€ Attention-Based Networks
    â”œâ”€â”€ Transformer
    â”œâ”€â”€ BERT / GPT
    â””â”€â”€ Vision Transformer (ViT)</pre>
  </div>

  <div class="categories">
    <!-- Feedforward Networks -->
    <div class="category-box">
      <div class="category-title">
        <span class="icon">â¡ï¸</span> Feedforward Networks
      </div>
      <p class="description">Data flows in one direction: input â†’ hidden layers â†’ output. No cycles or loops.</p>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ Perceptron</div>
        <div class="subcategory-desc">
          â€¢ Simplest neural network (single neuron)<br>
          â€¢ Binary classification only<br>
          â€¢ Linear decision boundaries
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ MLP (Multi-Layer Perceptron)</div>
        <div class="subcategory-desc">
          â€¢ Multiple hidden layers<br>
          â€¢ Non-linear decision boundaries<br>
          â€¢ Universal approximator
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ DNN (Deep Neural Network)</div>
        <div class="subcategory-desc">
          â€¢ Many hidden layers (depth â‰¥ 3)<br>
          â€¢ Feature hierarchy learning<br>
          â€¢ Requires careful training
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ CNN (Convolutional Neural Network)</div>
        <div class="subcategory-desc">
          â€¢ Specialized for image/spatial data<br>
          â€¢ Convolutional layers extract features<br>
          â€¢ State-of-the-art vision tasks
        </div>
      </div>
    </div>

    <!-- Recurrent Networks -->
    <div class="category-box">
      <div class="category-title">
        <span class="icon">ğŸ”„</span> Recurrent Networks
      </div>
      <p class="description">Data flows in cycles; maintains hidden state. Ideal for sequences and time-series.</p>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ RNN (Recurrent Neural Network)</div>
        <div class="subcategory-desc">
          â€¢ Basic recurrent architecture<br>
          â€¢ Processes sequences step-by-step<br>
          â€¢ Suffers from vanishing gradients
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ LSTM (Long Short-Term Memory)</div>
        <div class="subcategory-desc">
          â€¢ Memory cells (forget, input, output gates)<br>
          â€¢ Learns long-term dependencies<br>
          â€¢ NLP, speech recognition, time-series
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ GRU (Gated Recurrent Unit)</div>
        <div class="subcategory-desc">
          â€¢ Simplified LSTM variant<br>
          â€¢ Fewer parameters, faster training<br>
          â€¢ Similar performance to LSTM
        </div>
      </div>
    </div>

    <!-- Generative Networks -->
    <div class="category-box">
      <div class="category-title">
        <span class="icon">âœ¨</span> Generative Networks
      </div>
      <p class="description">Learn data distribution to generate new samples. Unsupervised learning.</p>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ Autoencoder</div>
        <div class="subcategory-desc">
          â€¢ Encoder-decoder architecture<br>
          â€¢ Dimensionality reduction<br>
          â€¢ Anomaly detection, feature learning
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ VAE (Variational Autoencoder)</div>
        <div class="subcategory-desc">
          â€¢ Probabilistic generative model<br>
          â€¢ Learns latent space distribution<br>
          â€¢ Generate new samples from latent codes
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ GAN (Generative Adversarial Network)</div>
        <div class="subcategory-desc">
          â€¢ Generator vs. Discriminator competition<br>
          â€¢ High-quality image generation<br>
          â€¢ Style transfer, super-resolution
        </div>
      </div>
    </div>

    <!-- Graph-Based Networks -->
    <div class="category-box">
      <div class="category-title">
        <span class="icon">ğŸ”—</span> Graph-Based Networks
      </div>
      <p class="description">Process graph-structured data. Nodes connected by edges with relationships.</p>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ GNN (Graph Neural Network)</div>
        <div class="subcategory-desc">
          â€¢ General framework for graphs<br>
          â€¢ Message passing between nodes<br>
          â€¢ Social networks, molecules, knowledge graphs
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ GCN (Graph Convolutional Network)</div>
        <div class="subcategory-desc">
          â€¢ Convolutional operations on graphs<br>
          â€¢ Spectral or spatial approach<br>
          â€¢ Node classification, link prediction
        </div>
      </div>
    </div>

    <!-- Attention-Based Networks -->
    <div class="category-box">
      <div class="category-title">
        <span class="icon">ğŸ‘ï¸</span> Attention-Based Networks
      </div>
      <p class="description">Focus on important parts of input. Parallel processing without recurrence.</p>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ Transformer</div>
        <div class="subcategory-desc">
          â€¢ Self-attention mechanism<br>
          â€¢ Parallel processing of sequences<br>
          â€¢ Foundation for modern NLP/vision
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ BERT / GPT</div>
        <div class="subcategory-desc">
          â€¢ Pre-trained transformer models<br>
          â€¢ BERT: bidirectional encoding<br>
          â€¢ GPT: autoregressive language model
        </div>
      </div>

      <div class="subcategory">
        <div class="subcategory-title">ğŸ”¹ Vision Transformer (ViT)</div>
        <div class="subcategory-desc">
          â€¢ Transformer for image classification<br>
          â€¢ Treats image as sequence of patches<br>
          â€¢ Competitive with CNNs
        </div>
      </div>
    </div>
  </div>

  <div class="legend">
    <h3>ğŸ“Š Classification Summary</h3>
    <div class="legend-item">
      <div class="legend-color color-feedforward"></div>
      <span><strong>Feedforward Networks:</strong> Unidirectional data flow. Best for supervised learning (images, classification).</span>
    </div>
    <div class="legend-item">
      <div class="legend-color color-recurrent"></div>
      <span><strong>Recurrent Networks:</strong> Cyclic structure with memory. Best for sequences (text, time-series, speech).</span>
    </div>
    <div class="legend-item">
      <div class="legend-color color-generative"></div>
      <span><strong>Generative Networks:</strong> Learn data distribution. Best for unsupervised learning, generation, sampling.</span>
    </div>
    <div class="legend-item">
      <div class="legend-color color-graph"></div>
      <span><strong>Graph-Based Networks:</strong> Process structured relationships. Best for social networks, molecules, recommendations.</span>
    </div>
    <div class="legend-item">
      <div class="legend-color color-attention"></div>
      <span><strong>Attention-Based Networks:</strong> Focus mechanism with parallelization. Best for NLP, vision, multimodal tasks.</span>
    </div>
  </div>

</div>

</body>
</html>
