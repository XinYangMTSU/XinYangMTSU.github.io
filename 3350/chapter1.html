<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Chapter 1: Intro to Machine Learning</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
  <style>
   body {
      font-family: 'Roboto', Arial, sans-serif;
      margin: 0;
      display: flex;
      background: #17191a;
      min-height: 100vh;
      color: #ff79c6; /* MAIN PINK FONT COLOR */
    }
    /* Sidebar */
    #sidebar {
      position: fixed;
      width: 250px;
      height: 100vh;
      overflow-y: auto;
      background: linear-gradient(135deg, #2a1e28 80%, #47223c 100%);
      color: #ffb3de;
      padding: 38px 24px 24px 28px;
      box-shadow: 2px 0 24px rgba(255,121,198,.12);
      z-index: 10;
    }
    #sidebar h2 {
      margin-top: 0;
      font-size: 1.1em;
      letter-spacing: 1px;
      text-transform: uppercase;
      color: #ffb3de;
      margin-bottom: 1.7em;
      text-align: left;
    }
    #sidebar ul {
      list-style: none;
      padding: 0;
      margin: 0;
    }
    #sidebar .subsections {
      margin-left: 1.5em;
      font-size: 0.94em;
    }
    #sidebar .subsections a {
      font-size: 0.94em;
      margin: 8px 0 8px 12px;
      padding-left: 16px;
      color: #ffb3de;
      border-left: 2px solid transparent;
      font-weight: 400;
      box-shadow: none;
      background: none;
      gap: 0.6em;
    }
    #sidebar .subsections a:hover, #sidebar .subsections a.active {
      color: #ff79c6;
      background: #21111b;
      border-left: 2px solid #ff79c6;
      font-weight: 500;
    }
    #sidebar a {
      display: flex;
      align-items: center;
      color: #ffb3de;
      text-decoration: none;
      margin: 16px 0 16px 10px;
      font-weight: 500;
      font-size: 1.08em;
      border-left: 3px solid transparent;
      padding-left: 14px;
      transition: background .19s, color .19s, border .19s;
      border-radius: 8px 0 0 8px;
      gap: 0.7em;
    }
    #sidebar a:hover, #sidebar a.active {
      color: #ff79c6;
      background: #21111b;
      border-left: 3px solid #ff79c6;
      font-weight: 700;
      box-shadow: 1px 2px 8px 1px #2d3436;
    }
    /* Main content */
    #content {
      margin-left: 270px;
      padding: 56px 6vw 56px 6vw;
      max-width: 900px;
      width: 100vw;
      background: #1a1d1f;
    }
    h1 {
      color: #ff79c6;
      font-size: 2.5em;
      font-weight: 800;
      margin-bottom: 0.4em;
      letter-spacing: -1px;
      text-shadow: 0 2px 16px rgba(255,121,198,.18);
    }
    section {
      margin-bottom: 55px;
      background: #222025;
      border-radius: 18px;
      box-shadow: 0 4px 30px rgba(255,121,198,.09);
      padding: 36px 32px 22px 32px;
      transition: box-shadow .24s;
      border-left: 7px solid #ff79c6;
      position: relative;
    }
    section:hover {
      box-shadow: 0 10px 34px 3px rgba(255,121,198,0.13);
      border-left: 7px solid #ffb3de;
    }
    section h3 {
      border-bottom: 2px solid #ff79c6;
      padding-bottom: 8px;
      margin-top: 0;
      color: #ff79c6;
      font-size: 1.5em;
      font-weight: 700;
      letter-spacing: 0.5px;
      margin-bottom: 14px;
    }
    section h4 {
      font-size: 1.18em;
      color: #ffb3de;
      margin-bottom: 5px;
      margin-top: 30px;
      font-weight: 600;
      border-bottom: 1px solid #ffb3de;
      padding-bottom: 2px;
    }
    pre {
      background: #19121a;
      color: #ffb3de;
      padding: 15px 18px;
      border-radius: 8px;
      font-size: 1.04em;
      line-height: 1.7;
      overflow-x: auto;
      box-shadow: 0 2px 10px rgba(255,121,198,0.11);
    }
    ul {
      margin-left: 2.1em;
      margin-bottom: 0;
    }
    footer {
      margin-top: 46px;
      text-align: center;
      color: #ffb3de;
      font-size: 1.09em;
      letter-spacing: 1px;
      padding: 22px 0 14px 0;
      border-top: 1px solid #402138;
      background: none;
      font-family: 'Roboto', Arial, sans-serif;
      font-weight: 500;
    }
    #sidebar::-webkit-scrollbar {
      width: 7px;
      background: #47223c;
    }
    #sidebar::-webkit-scrollbar-thumb {
      background: #ff79c6;
      border-radius: 6px;
    }
    @media (max-width: 950px) {
      #sidebar {
        display: none;
      }
      #content {
        margin-left: 0;
        padding: 18px 4vw 30px 4vw;
      }
    }

    /* Links */
    a, a:visited {
      color: #ff79c6;
      text-decoration: underline;
      transition: color 0.2s;
    }
    a:hover, a:focus {
      color: #fff52e;
      background: #19121a;
      text-decoration: underline;
    }
    section#references a, section#references a:visited {
      color: #ff79c6;
      font-weight: 600;
    }
    section#references a:hover, section#references a:focus {
      color: #fff52e;
      background: #19121a;
    }

    .row{margin:10px 0 16px;padding:12px 14px;background:rgba(255,255,255,.03);border:1px solid rgba(255,255,255,.08);border-radius:14px}
    .row .hdr{display:flex;align-items:center;gap:.6rem;color:var(--pink2);font-weight:800;margin-bottom:6px}
    .row .hdr .y{min-width:120px;display:inline-flex;align-items:center;gap:.45rem}
    .row .lead{color:var(--ink);font-weight:700;margin-bottom:4px}
    .row .sub{color:var(--ink);opacity:.95}
    .note{margin-top:12px;padding:12px 14px;border:1px dashed rgba(255,255,255,.18);border-radius:12px;background:rgba(255,255,255,.04);color:var(--ink)}
    .two{display:grid;grid-template-columns:1fr;gap:12px}
    @media (min-width:860px){.two{grid-template-columns:1fr 1fr}}
  .row{margin:10px 0 16px;padding:12px 14px;background:rgba(255,255,255,.03);border:1px solid rgba(255,255,255,.08);border-radius:14px}
    .row .hdr{display:flex;align-items:center;gap:.6rem;color:var(--pink2);font-weight:800;margin-bottom:6px}
    .row .hdr .y{min-width:120px;display:inline-flex;align-items:center;gap:.45rem}
    .row .lead{color:var(--ink);font-weight:700;margin-bottom:4px}
    .row .sub{color:var(--ink);opacity:.95}
    .note{margin-top:12px;padding:12px 14px;border:1px dashed rgba(255,255,255,.18);border-radius:12px;background:rgba(255,255,255,.04);color:var(--ink)}
    .two{display:grid;grid-template-columns:1fr;gap:12px}
    
  </style>
</head>
<body>
<nav id="sidebar">
  <h2><i class="fas fa-book"></i> Contents</h2>
  <ul>
    <li><a href="#what-is-ml"><i class="fas fa-robot"></i>1. What is Machine Learning?</a></li>
    <li><a href="#types-ml"><i class="fas fa-layer-group"></i>2. Types of ML Systems</a></li>
    <li>
      <a href="#supervised"><i class="fas fa-chalkboard-teacher"></i>3. Supervised Learning</a>
      <div class="subsections">
        <a href="#regression">3.1 Regression</a>
        <a href="#classification">3.2 Classification</a>
      </div>
    </li>
    <li>
      <a href="#unsupervised"><i class="fas fa-search"></i>4. Unsupervised Learning</a>
      <div class="subsections">
        <a href="#clustering">4.1 Clustering</a>
        <a href="#dim-reduction">4.2 Dimensionality Reduction</a>
      </div>
    </li>
    <li>
      <a href="#reinforcement"><i class="fas fa-gamepad"></i>5. Reinforcement Learning</a>
      <div class="subsections">
        <a href="#value-based">5.1 Value-Based Methods</a>
        <a href="#policy-based">5.2 Policy-Based Methods</a>
      </div>
    </li>
    <li>
      <a href="#adversarial"><i class="fas fa-magic"></i>6. Adversarial Learning</a>
      <div class="subsections">
        <a href="#gans">6.1 GANs</a>
        <a href="#adversarial-training">6.2 Adversarial Training for Robustness</a>
        <!--
        <a href="#autoregressive">6.2 Autoregressive Models</a>
        <a href="#diffusion">6.3 Diffusion Models</a>
        -->
      </div>
    </li>

    <li><a href="#ai-ml-dl-diagram"><i class="fas fa-link"></i>7. Venn Diagram for AI, ML, and DL</a></li>
    <li><a href="#ml-history"><i class="fas fa-link"></i>8. Short Timeline for History</a></li>
    <li><a href="#nobel-ml"><i class="fas fa-link"></i>üéñÔ∏è Nobel Prizes for Machine Learning</a></li>
    
    <li><a href="#references"><i class="fas fa-link"></i>References</a></li>
  </ul>
</nav>

<main id="content">
  <h1>Chapter 1: Introduction to Machine Learning</h1>

  <section id="what-is-ml">
    <h3>1. What is Machine Learning?</h3>
    <p>
      Machine learning (ML) is the process of teaching computers to make decisions or predictions based on data, 
      rather than through explicit programming. It powers many modern technologies, 
      from generative AI that creates text and images to autonomous robotics and self-driving cars.
    </p>

    <h4>How does it work?</h4>
    <ul>
      <li>You give the computer a lot of examples (data).</li>
      <li>The computer finds patterns in that data.</li>
      <li>It uses those patterns to make predictions or decisions on new, unseen data.</li>
    </ul>

    <h4>Example:</h4>
    <ul>
      <li>If you want a computer to recognize cats in photos, you don‚Äôt write a program like:
      "If it has whiskers, pointy ears, and fur, then it‚Äôs a cat."</li>
      <li>Instead, you show it thousands of labeled pictures (cats vs. not cats).</li>
      <li>The computer learns what features are common in cat photos and uses that to predict whether new photos contain cats.</li>
    </ul>
    
  </section>

  <section id="types-ml">
    <h3>2. Types of ML Systems</h3>

    <h4>The Core Learning Paradigms:</h4>
    <ul>
      <li><strong>Supervised Learning</strong>: Learn a mapping from input to output with labeled data (e.g., classification, regression).</li>
      <li><strong>Unsupervised Learning</strong>: Find hidden patterns or structures in data without explicit labels (e.g., clustering, dimensionality reduction).</li>
      <li><strong>Reinforcement Learning</strong>: Learn to make a sequence of decisions by receiving rewards or penalties from the environment to maximize cumulative reward.</li>
      
      <li><strong>Adversarial Learning</strong>: Two systems competing against each other, where one tries to fool the other while the other tries to detect deception.</li>
      

      <!--
      <li><strong>Generative AI</strong>: Create new content (text, images, audio) that mimics real data distributions.</li>
      Note: Generative AI is a capability, not a separate learning paradigm; often trained with self-supervised learning and sometimes fine-tuned with RL.
      -->
    </ul>
    
  </section>

  <section id="supervised">
    <h3>3. Supervised Learning</h3>
    <p>
      Supervised learning is a type of machine learning where the computer learns from labeled data‚Äîthat means each example 
      in your data comes with the correct answer (the "label").
    </p>

    <h4>Goal: </h4>
    <p>
    Learn a mapping from input (data) to output (label), so that the computer can make predictions about new, unseen data.
    </p>
    
    <h4>
      The two main types of supervised learning are:
    </h4>
    
    <div id="regression">
      <h4>3.1 Regression</h4>
      <p>Regression algorithms <b><font color="red">predict numeric values</font></b> (e.g., house prices, temperature).
      Common methods include:
      </p>
      <ul>
        <li><strong>Linear Regression:</strong> Predicts a continuous outcome based on a linear relationship between input features and the target variable.</li>
        <li><strong>Ridge Regression (L2 Regularization): Linear regression with a penalty for large coefficients to prevent overfitting.</strong></li>
        <li><strong>Lasso Regression (L1 Regularization): Similar to ridge, but can shrink some coefficients to zero, performing feature selection.</strong></li>
      </ul>
  
      
    </div>
    <div id="classification">
      <h4>3.2 Classification</h4>
      <p>Classification algorithms <b><font color="red">predicte categories</font> </b> (e.g., spam detection, image recognition).
      Common methods include:
      </p>
      
      <ul>
        <li><strong>Logistic Regression:</strong> Models the probability that an input belongs to a certain category; suitable for binary and multiclass problems.</li>
        <li><strong>K-Nearest Neighbors (KNN):</strong> Assigns a class based on the majority class among the k closest data points.</li>
        <li><strong>Support Vector Machines (SVM):</strong> Finds the optimal boundary (hyperplane) that best separates different classes.</li>
        <li><strong>Decision Tree Classification:</strong> Uses a tree-like structure to make decisions and assign labels.</li>
        <li><strong>Naive Bayes:</strong> Probabilistic classifier based on Bayes‚Äô theorem; effective for text classification and spam detection.</li>
        <li><strong>Neural Network Classification:</strong> Uses artificial neural networks to model complex patterns for multi-class and binary problems.</li>
      </ul>
      
    </div>
  </section>

  <section id="unsupervised">
    <h3>4. Unsupervised Learning</h3>
    <p>
      Unsupervised learning is a type of machine learning where the computer learns patterns or structures from data that 
      is not labeled‚Äîmeaning we don‚Äôt provide the correct answers.
    </p>

    <h4>Goal:</h4>
    <p>
      Find hidden patterns, groupings, or features in the data without knowing what the "right" answer is.
    </p>

    <h4>
      The two main types of unsupervised learning are:
    </h4>
    
    <div id="clustering">
      <h4>4.1 Clustering</h4>
      <p>Clustering algorithms group data points into clusters based on similarity or distance. 
        Common methods include: </p>
      <ul>
        <li><strong>K-Means:</strong> Partitions data into a predefined number (K) of clusters by iteratively 
          assigning points to the nearest cluster centroid and updating centroids, optimizing within-cluster similarity.</li>
        <li><strong>Hierarchical Clustering:</strong> Builds a tree-like structure (dendrogram) of nested clusters by 
          either progressively merging smaller clusters (agglomerative) or splitting larger clusters (divisive)</li>
      </ul>
    </div>
    <div id="dim-reduction">
      <h4>4.2 Dimensionality Reduction</h4>
      <p>Dimensionality reduction algorithms reduce the number of input variables or features, making data easier to visualize and process. Popular techniques include:</p>
      <ul>
        <li><strong>PCA (Principal Component Analysis):</strong> Transforms data to a new set of orthogonal axes that maximize variance.</li>
        <li><strong>ICA (Independent Component Analysis):</strong> Decomposes a multivariate signal into independent non-Gaussian components, often used in signal processing and brain imaging.</li>
      </ul>
    </div>
  </section>

  <section id="reinforcement">
    <h3>5. Reinforcement Learning</h3>
    <p>
      Reinforcement learning (RL) is a paradigm where agents learn optimal strategies by interacting with an environment and receiving feedback as rewards or penalties.
      RL is for problems where you need to make a sequence of decisions over time, not just predict a single answer.
    </p>

    <p>
      Reinforcement Learning (RL) is a type of machine learning where an agent (like a robot, computer program, or character in a game) learns how to act by 
      interacting with an environment and receiving feedback in the form of rewards (positive points) or penalties (negative points), 
      and gradually learns the best actions to achieve a goal.
    </p>
    
    <h4>Goal: </h4>
    <p>
      Learn to make the best possible decisions to achieve the highest total reward in the long run.
    </p>
    
    <h4>
      Reinforcement learning methods can be broadly grouped as:
    </h4>
    
    <div id="value-based">
      <h4>5.1 Value-Based Methods</h4>
      <p>
        Value-based methods estimate the expected reward of actions or states. The agent chooses actions to maximize these values.<br>
        <ul>
          <li><strong>Q-Learning:</strong> Learns the value of taking a given action in a given state.</li>
        </ul>
      </p>
    </div>
    <div id="policy-based">
      <h4>5.2 Policy-Based Methods</h4>
      <p>
        Policy-based methods directly optimize the policy that decides actions. These are often used when value-based methods are impractical.<br>
        <ul>
          <li><strong>Policy Gradient methods:</strong> optimize the policy using gradient ascent.</li>
        </ul>
      </p>
    </div>

    <H4>How is RL Different from Other ML Types?</H4>

    <ul>
      <li>In regression or classification, you learn from labeled data (inputs with correct answers).</li>
      <li>In <b>RL</b>, you learn from interacting, trial-and-error: you try something, see what happens, and get better over time.</li>
    </ul>
    
    <h4>Some real-world problems:</h4>

    <b>1. Game Playing: </b>
    <ul>
        <li><b>Chess, Go, Poker, Video Games:</b> RL learns strategies by trial and error. </li>
        <li><b>Example:</b> AlphaGo beat world champions‚Äînot by being told moves, but by learning to play over millions of games 
        and maximizing win rewards.</li>
     </ul>
    
      <b>2. Robotics: </b>
      <ul>
        <li><b>Self-driving cars, walking robots, robotic arms:</b>
        Robots need to make a series of decisions (e.g., turn left, speed up, pick up an object). 
          RL helps them learn these behaviors from experience in simulated or real worlds.</li>
      </ul>
    
  </section>

  <section id="adversarial">
    <h3>6. Adversarial Learning</h3>
    <p>
      Adversarial Learning is a learning paradigm where two AI systems compete against each other in a game-like setup.
      Unlike supervised/unsupervised/reinforcement learning, adversarial learning uses competition and minimax game theory as the core learning mechanism. 
      The two systems push each other to improve through their adversarial relationship.
    </p>
   <p>Adversarial Learning is like having two AI systems play a continuous game against each other 
     - one tries to create something (like fake images), while the other tries to detect 
     if it's real or fake. Through this competition, both systems get better at their 
     respective tasks, similar to how athletes improve by training against strong opponents.</p>

    <h4>Goal: </h4>
    <p>
      Create more robust, creative, and reliable AI systems through competitive training, where models learn to handle challenging scenarios and generate high-quality outputs.
    </p>

    <h4>
      Adversarial learning methods can be broadly grouped as:
    </h4>
    <div id="gans">
      <h4>6.1 Generative Adversarial Networks (GANs)</h4>
       <p>
        Two neural networks compete: a generator creates fake data, while a discriminator tries to distinguish real from fake data.<br>
        <ul>
          <li><strong>Generator:</strong> Learns to create realistic fake images, text, or other data.</li>
          <li><strong>Discriminator:</strong> Learns to detect whether data is real or artificially generated.</li>
        </ul>
      </p>
      <p>
        GANs utilize a generator and a discriminator in a competitive process to produce increasingly realistic outputs. They are famous for generating realistic images and videos.
        <strong>Examples:</strong> StyleGAN3(high-fidelity image synthesis)
      </p>
    </div>

   <div id="adversarial-training">
      <h4>6.2 Adversarial Training for Robustness</h4>
      <p>
        Models are trained to defend against adversarial attacks - small, intentional perturbations designed to fool AI systems.<br>
        <ul>
          <li><strong>Adversarial Examples:</strong> Inputs specifically crafted to cause misclassification.</li>
          <li><strong>Robust Training:</strong> Training models to resist these attacks and maintain accuracy.</li>
        </ul>
      </p>
    </div>

    <h4>Some real-world problems:</h4>
    <b>1. Creative Content Generation: </b>
    <ul>
        <li><b>Image Creation, Art, Deepfakes:</b> GANs can generate photorealistic faces, artwork, or synthetic media.</li>
        <li><b>Example:</b> DALL-E and Midjourney use adversarial principles to create images from text descriptions, 
        learning to generate increasingly realistic and creative outputs.</li>
     </ul>
      <b>2. Cybersecurity and AI Safety: </b>
      <ul>
        <li><b>Spam detection, fraud prevention, autonomous vehicle safety:</b>
        Adversarial training helps models defend against attacks where malicious actors try to fool AI systems. 
        This is crucial for security-critical applications like email filters or self-driving cars.</li>
      </ul>

      <b>3. Data Augmentation and Privacy: </b>
      <ul>
        <li><b>Medical imaging, financial modeling:</b>
        GANs can generate synthetic data that looks real but protects privacy, 
        helping train models when real data is limited or sensitive.</li>
      </ul>
    
    <!--
    <div id="autoregressive">
      <h4>6.2 Autoregressive Models</h4>
      <p>
        Autoregressive (AR) models are sequence generators that produce outputs one step at a time, with each new step conditioned on all previous steps.
        These models generate data one step at a time, with each output depending on previous outputs. <strong>Examples:</strong> chatGPT (text/code generation), Mureka (text-to-music).
      </p>
    </div>
    <div id="diffusion">
      <h4>6.3 Diffusion Models</h4>
      <p>
        Diffusion models are generative models that learn to reverse a noising process.
        Diffusion models create data by learning to gradually denoise random input, producing some of the highest quality images to date. <strong>Examples:</strong> DALL¬∑E 2 (text-to-image), OpenAI Sora (text-to-video/image).
      </p>
    </div>
    -->
  </section>


  <section id="ai-ml-dl-diagram">
  <h3>7. AI, Machine Learning, Deep Learning, and Generative AI: How Do They Relate? </h3>
    
  <div style="display:flex; flex-wrap:wrap; gap:28px; align-items:center;">
   <svg width="420" height="280" viewBox="0 0 420 280" style="background:transparent;">
                <!-- AI Circle (outermost) -->
                <ellipse cx="210" cy="140" rx="190" ry="115" fill="#ffb3de22" stroke="#ff79c6" stroke-width="2"/>
                <text x="65" y="80" fill="#ff79c6" font-size="1.45em" font-weight="bold">AI</text>
                <!-- ML Circle -->
                <ellipse cx="210" cy="150" rx="130" ry="80" fill="#ff79c660" stroke="#ff79c6" stroke-width="2"/>
                <text x="145" y="135" fill="#ff79c6" font-size="1.2em" font-weight="bold">ML</text>
                <!-- DL Circle -->
                <ellipse cx="240" cy="165" rx="75" ry="45" fill="#ff79c6" fill-opacity="0.18" stroke="#ff79c6" stroke-width="2"/>
                <text x="185" y="155" fill="#ff79c6" font-size="1em" font-weight="bold">DL</text>
                <!-- Generative AI Circle (innermost) -->
                <ellipse cx="255" cy="175" rx="30" ry="18" fill="#ff79c6" fill-opacity="0.4" stroke="#ff79c6" stroke-width="2"/>
                <text x="235" y="180" fill="#ff79c6" font-size="0.7em" font-weight="bold">Gen AI</text>
            </svg>
    
    <ul style="flex:1; min-width:220px;">
      <li><b>Artificial Intelligence (AI):</b> The broadest field, aiming to make computers ‚Äúsmart‚Äù by mimicking human intelligence.</li>
      <li><b>Machine Learning (ML):</b> A subset of AI, where computers learn from data to make predictions.</li>
      <li><b>Deep Learning (DL):</b> A specialized subset of ML, using neural networks with many layers (deep neural networks) to learn from large, complex datasets.</li>
      <li><b>Generative AI (Gen AI):</b> AI systems that can create new content (text, images, code, etc.) by learning patterns from training data. Often uses deep learning techniques.</li>
    </ul>
  </div>
  <br>
  <center>
  <img src="./images/AI2.webp" width="400px" height="600px">
  </center>
</section>


  <section id="ml-history">
  <h3>8. A Brief History of Machine Learning</h3>

      <div class="row">
        <div class="hdr"><span class="y"><i class="fa-solid fa-robot"></i> 1950s</span> AI begins; Turing‚Äôs test for intelligence</div>
        <div class="lead">What happened</div>
        <div class="sub">
          In 1950, British mathematician <b>Alan Turing</b> published a paper called "Computing Machinery and Intelligence" where he proposed what became known as the <b>Turing Test</b>. 
          The test works like this: a human evaluator has text-based conversations with both a human and a machine, without knowing which is which. 
          If the evaluator can't reliably tell them apart, the machine passes the test and could be considered "intelligent."
        </div>
        <div class="lead" style="margin-top:6px">Why it matters</div>
        <div class="sub">
          Before Turing, the question "Can machines think?" was largely philosophical. Turing reframed it as a practical, measurable challenge: instead of debating what thinking "really" is, 
          he focused on whether a machine could convincingly demonstrate intelligent behavior through conversation.
          This proposal essentially launched the field of AI research. It gave researchers a concrete goal and sparked decades of work on what were initially "symbolic" or "rule-based" 
          systems‚Äîearly AI programs that used logical rules and symbol manipulation to try to mimic human reasoning.</div>
      </div>

      <div class="row">
        <div class="hdr"><span class="y"><i class="fa-solid fa-graduation-cap"></i> 1959</span> ‚ÄúMachine Learning‚Äù is named</div>
        <div class="lead">What happened</div>
        <div class="sub">
        In 1959, IBM researcher <b>Arthur Samuel</b> was working on a computer program that could play checkers. What made his approach special wasn't just that 
          the computer could play‚Äîit was that the program got better over time by playing against itself and learning from experience, rather than just following pre-written rules.
          <br><br>
          Samuel used the phrase "<b>machine learning</b>" to describe this approach, defining it as giving computers "the ability to learn without being explicitly programmed." 
          This was a fundamentally different philosophy from the rule-based AI systems that dominated the 1950s.
        </div>
        <div class="lead" style="margin-top:6px">Why it matters</div>
        <div class="sub">
          Samuel's definition captures what we now consider the essence of machine learning: instead of programmers writing detailed instructions for every possible situation, 
          you feed the system data and let it discover patterns on its own. 
          <br><br>
          This "data-driven spirit" that Samuel described is exactly how modern machine learning works‚Äîwhether it's Netflix recommending movies, smartphones recognizing faces, 
          or AI systems like ChatGPT learning from vast amounts of text. The core idea remains the same: give machines data, let them find patterns, and 
          watch them improve through experience rather than explicit programming.
          <br><br>
          Samuel essentially shifted AI from "tell the computer exactly what to do" to "show the computer examples and let it figure out what to do."
          </div>
      </div>

      <div class="row">
        <div class="hdr"><span class="y"><i class="fa-solid fa-brain"></i> 1980s</span> Backpropagation makes neural nets trainable</div>
        <div class="lead">What happened</div>
        <div class="sub"> Before the 1980s, neural networks were very limited: they could only handle very simple problems. </div>
        
        <div class="sub">In 1986, <b>David E. Rumelhart</b>, <b>Geoffrey E. Hinton</b>, and <b>Ronald J. Williams</b> popularized an algorithm called <b>backpropagation</b> (short for backward propagation of errors).
        Backpropagation gave a systematic way for <b>multi-layer neural networks</b> (also called deep networks) to adjust their internal connections (weights) by learning from mistakes.
        </div>
        <div class="lead" style="margin-top:6px">Why it matters</div>
        <div class="sub">This discovery transformed neural networks from a theoretical curiosity into a practical tool for solving real problems.
          Backpropagation made it possible to train deeper networks (more than one hidden layer).
          This breakthrough paved the way for <b>convolutional neural networks</b> (CNNs) ‚Äî early versions appeared soon after for tasks like recognizing handwritten digits.
          (e.g., <b>Yann LeCun</b> and collaborators).</div>
      </div>

      <div class="row">
        <div class="hdr"><span class="y"><i class="fa-solid fa-chess"></i> 1997</span> Deep Blue beats Garry Kasparov</div>
        <div class="lead">What happened</div>
        <div class="sub"><b>IBM Deep Blue</b> defeated world chess champion <b>Garry Kimovich Kasparov</b>.</div>
        <div class="lead" style="margin-top:6px">Important nuance</div>
        <div class="sub">Deep Blue relied on large‚Äëscale search and expert evaluation (not modern ML). It showed that careful algorithms + massive compute can master complex tasks, but it wasn‚Äôt a learning breakthrough.</div>
      </div>

      <div class="row">
        <div class="hdr"><span class="y"><i class="fa-solid fa-camera"></i> 2012</span> The Deep Learning ‚ÄúImageNet moment‚Äù (AlexNet)</div>
        <div class="lead">What happened</div>
        <div class="sub"><b>Alex Krizhevsky</b>, <b>Ilya Sutskever</b>, and <b>Geoffrey E. Hinton</b> trained a large GPU‚Äëaccelerated CNN (<b>AlexNet</b>) and won the ImageNet competition by a wide margin.</div>
        <div class="lead" style="margin-top:6px">Why it matters</div>
        <div class="sub">Error rates dropped dramatically; this ignited the deep learning wave across vision, then speech and language.</div>
      </div>

      <div class="row">
        <div class="hdr"><span class="y"><i class="fa-solid fa-rocket"></i> 2016‚Äìpresent</span> Deep learning everywhere</div>
        <div class="lead">Examples</div>
        <div class="sub"><b>AlphaGo</b> (2016): deep reinforcement learning + search mastered Go. <br/>
          <b>Transformers</b> (2017): ‚ÄúAttention Is All You Need‚Äù by <b>Ashish Vaswani</b>, <b>Noam Shazeer</b>, <b>Niki Parmar</b>, <b>Jakob Uszkoreit</b>, <b>Llion Jones</b>, <b>Aidan N. Gomez</b>, <b>≈Åukasz Kaiser</b>, and <b>Illia Polosukhin</b> enabled today‚Äôs large language models (GPT family, BERT). <br/>
          <b>Generative models</b> (2021‚Äì): diffusion and modern autoregressive models power realistic image/video/audio generation (e.g., DALL¬∑E, Stable Diffusion) and advanced assistants (ChatGPT).
        </div>
        <div class="lead" style="margin-top:6px">Why it matters</div>
        <div class="sub">With data, compute (GPUs/TPUs), and better algorithms, ML moved from niche successes to broad, real‚Äëworld impact (vision, speech, language, robotics, autonomous driving).</div>
      </div>

      <div class="note">
        <div class="hdr"><b><i class="fa-regular fa-snowflake"></i> AI winters:</b> </div>
       
        <b>‚ÄúAI winters‚Äù</b> are the industry‚Äëwide <b>cool‚Äëdowns</b> that happen when excitement and promises get ahead of what the tech can actually do, leading to funding cuts and skepticism. 
          The two biggest were in the 1970s and the late 1980s‚Äìearly 1990s.
        <br><br>
        <div class="sub"><span class="y"><i class="fa-solid fa-temperature-low"></i> 1st AI winter (~1974‚Äì1980)</span></div>
        <div class="sub">Symbolic/rule‚Äëbased systems stalled; limited compute/data; critical reports (e.g., the UK‚Äôs <b>Lighthill Report</b>, led by <b>Sir James Lighthill</b>) prompted <b>funding cuts</b>.</div>
        <br>
        <div class="sub"><span class="y"><i class="fa-solid fa-temperature-arrow-down"></i> 2nd AI winter (~1987‚Äì1993)</span></div>
        <div class="sub">The <b>expert‚Äësystems</b> boom burst‚Äîsystems were brittle and costly to maintain; specialized AI hardware markets (e.g., <b>Lisp machines</b>) collapsed; government programs were scaled back.</div>
      </div>
          
        <div class="note"><b><i class="fa-solid fa-bolt"></i> Why the recent boom:</b> three forces aligned‚Äîbig data, massive compute, and better architectures/objectives (backprop ‚Üí CNNs ‚Üí Transformers; likelihood/contrastive/diffusion training).</div>
  
</section>

  <section id="latest-ai-trends">
  <h3>9. The Latest in AI, ML, and Deep Learning (2024‚Äì2025)</h3>
  <ul>
    <li><b>OpenAI Sora:</b> A powerful AI model that generates realistic videos from simple text prompts‚Äîpushing the frontier of generative AI. (<a href="https://openai.com/sora/" target="_blank">Official Site</a>)</li>
    <li><b>Google Gemini:</b> Google‚Äôs latest multimodal AI, combining text, images, audio, and code for seamless cross-modal reasoning. (<a href="https://deepmind.google/technologies/gemini/" target="_blank">Learn more</a>)</li>
    <li><b>Meta Llama 4:</b> An open-source large language model that rivals GPT-4 in benchmarks‚Äîused for chatbots, code, and more. (<a href="https://ai.meta.com/llama/" target="_blank">Meta AI</a>)</li>
    <li><b>AlphaFold:</b> DeepMind‚Äôs new version predicts protein structures and interactions, revolutionizing drug discovery. (<a href="https://deepmind.google/science/alphafold/" target="_blank">AlphaFold</a>)</li>
    <li><b>AI Art & Video Generation:</b> Tools like Midjourney, Stable Diffusion 3, and Runway ML are empowering creators to generate images and films with AI.</li>
    <li><b>AI Agents:</b> Next-generation AI agents (e.g., Devin AI) can perform multi-step tasks, code, and even operate software autonomously.</li>
  </ul>
  <div style="display: flex; flex-wrap: wrap; gap: 28px; margin-top: 18px;">
    <!-- Sora Video -->
    <div style="flex: 1 1 320px; min-width: 320px; max-width: 420px;">
      <iframe width="100%" height="225" src="https://www.youtube.com/embed/360ZqfabuPQ" title="OpenAI Sora Demo" frameborder="0" allowfullscreen></iframe>
      <p style="margin-top:8px;color:#ffb3de">OpenAI Sora: Text-to-Video Demo</p>
    </div>
    <!-- Gemini Video -->
    <div style="flex: 1 1 320px; min-width: 320px; max-width: 420px;">
      <iframe width="100%" height="225" src="https://www.youtube.com/embed/pEmCgIGpIoo" title="Google Gemini AI Demo" frameborder="0" allowfullscreen></iframe>
      <p style="margin-top:8px;color:#ffb3de">Google Gemini: Multimodal AI</p>
    </div>
    <!-- Llama  Video -->
    <div style="flex: 1 1 320px; min-width: 320px; max-width: 420px;">
      <iframe width="100%" height="225" src="https://www.youtube.com/embed/hErSrkrCg6k" title="Meta Llama Overview" frameborder="0" allowfullscreen></iframe>
      <p style="margin-top:8px;color:#ffb3de">Meta Llama: Open Source LLM</p>
    </div>
    <!-- AlphaFold  Video -->
    <div style="flex: 1 1 320px; min-width: 320px; max-width: 420px;">
      <iframe width="100%" height="225" src="https://www.youtube.com/embed/P_fHJIYENdI" title="AlphaFold 3 Explainer" frameborder="0" allowfullscreen></iframe>
      <p style="margin-top:8px;color:#ffb3de">AlphaFold: Protein Structure</p>
    </div>
  </div>
  <p style="color:#ffb3de; margin-top:16px; font-size:1.07em;">
    <b>Explore more:</b> <a href="https://www.marktechpost.com/" target="_blank">MarkTechPost</a>, <a href="https://huggingface.co/" target="_blank">Hugging Face</a>, <a href="https://www.youtube.com/@TwoMinutePapers" target="_blank">Two Minute Papers (YouTube)</a>
  </p>
</section>

  
  <section id="nobel-ml">
  <h3>üéñÔ∏è Nobel Prizes for Machine Learning (2024)</h3>
  <ul>
    <li>
      <strong><a href="https://www.nobelprize.org/all-nobel-prizes-2024/?utm_source=chatgpt.com" target="_blank">Physics</a>:</strong> 
      <b>John J. Hopfield</b> and <b>Geoffrey E. Hinton</b> received the 2024 Nobel Prize in Physics for their ‚Äúfoundational discoveries and 
      inventions that enable machine learning with artificial neural networks‚Äù‚Äîspecifically: the <b>Hopfield network</b> 
      (an associative memory model) and the <b>Boltzmann machine</b> (a learning model capable of discovering features autonomously)
    </li>
    <br>
    <li>
      <strong><a href="https://www.nobelprize.org/all-nobel-prizes-2024/?utm_source=chatgpt.com" target="_blank">Chemistry</a>:</strong> 
      The 2024 Nobel Prize in Chemistry was awarded half to <b>David Baker</b> for computational protein design, 
      and the other half to both <b>Demis Hassabis</b> and <b>John M. Jumper</b> for their AI-driven work in 
      protein structure prediction‚Äînotably through DeepMind's pioneering <b>AlphaFold</b> model
    </li>
  </ul>
  <p>
    These awards illustrate machine learning‚Äôs deep impact‚Äîfrom theoretical underpinnings to revolutionizing biology.
  </p>
</section>


  <section id="references">
    <h3>References</h3>
    <ul>
      <li>
        <a href="https://developers.google.com/machine-learning/crash-course" target="_blank">
          Google Machine Learning Crash Course
        </a>
      </li>
      <li>
        <a href="https://scikit-learn.org/stable/user_guide.html" target="_blank">
          scikit-learn User Guide
        </a>
      </li>
      <li>
        <a href="https://www.coursera.org/learn/machine-learning" target="_blank">
          Andrew Ng's Machine Learning (Coursera)
        </a>
      </li>
      <li>
        <a href="https://www.deeplearning.ai/short-courses/" target="_blank">
          DeepLearning.AI Short Courses
        </a>
      </li>
      <li>Scholar GPT</li>
    </ul>
  </section>
  <footer>
    &copy; 2025 Xin Yang <br>
    Department of Computer Science <br>
    Middle Tennessee State University <br>
  </footer>
</main>

<script>
  // Smooth scrolling & highlight active link
  const sidebarLinks = document.querySelectorAll('#sidebar a');
  sidebarLinks.forEach(anchor => {
    anchor.onclick = function(e) {
      e.preventDefault();
      document.querySelector(this.getAttribute('href'))
        .scrollIntoView({ behavior: 'smooth' });
    };
  });

  // Active link highlight on scroll
  const sectionIds = Array.from(sidebarLinks).map(l => l.getAttribute('href'));
  window.addEventListener('scroll', () => {
    let current = sectionIds[0];
    for (const id of sectionIds) {
      const section = document.querySelector(id);
      if (section && section.getBoundingClientRect().top - 80 < 0) {
        current = id;
      }
    }
    sidebarLinks.forEach(link => link.classList.remove('active'));
    const activeLink = document.querySelector(`#sidebar a[href="${current}"]`);
    if (activeLink) activeLink.classList.add('active');
  });
</script>

</body>
</html>
