<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Gradient Descent: Epochs & Batch Size</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <style>
    body {
      margin: 0;
      padding: 20px;
      background: #17191a;
      font-family: 'Roboto', Arial, sans-serif;
      color: #ff79c6;
      min-height: 100vh;
    }

    .container {
      max-width: 1400px;
      margin: 0 auto;
      background: #222025;
      border-radius: 18px;
      padding: 40px;
      box-shadow: 0 4px 30px rgba(255,121,198,.09);
      border-left: 7px solid #ff79c6;
    }

    h1 {
      color: #ff79c6;
      text-align: center;
      font-size: 2.5em;
      margin-bottom: 10px;
    }

    .subtitle {
      color: #ffb3de;
      text-align: center;
      font-size: 1.1em;
      margin-bottom: 40px;
    }

    .section {
      background: #2a1e28;
      border: 2px solid #ff79c6;
      border-radius: 12px;
      padding: 25px;
      margin-bottom: 30px;
    }

    .section h2 {
      color: #ff79c6;
      margin-top: 0;
      border-bottom: 2px solid #ffb3de;
      padding-bottom: 10px;
    }

    .code-block {
      background: #19121a;
      padding: 20px;
      border-radius: 8px;
      border-left: 4px solid #50fa7b;
      margin: 15px 0;
      font-family: 'Courier New', monospace;
      color: #fff52e;
      overflow-x: auto;
      font-size: 0.95em;
      line-height: 1.6;
    }

    .formula {
      background: #19121a;
      padding: 20px;
      border-radius: 8px;
      margin: 15px 0;
      text-align: center;
      color: #fff52e;
      font-size: 1.1em;
      border: 1px solid #50fa7b;
    }

    .example-box {
      background: #1e1e2f;
      border: 2px solid #8be9fd;
      border-radius: 12px;
      padding: 20px;
      margin: 20px 0;
    }

    .example-box h3 {
      color: #8be9fd;
      margin-top: 0;
    }

    .example-item {
      background: #19121a;
      padding: 15px;
      margin: 10px 0;
      border-left: 4px solid #50fa7b;
      border-radius: 6px;
      color: #ffb3de;
    }

    .example-item strong {
      color: #fff52e;
    }

    .flow-diagram {
      background: #19121a;
      padding: 20px;
      border-radius: 8px;
      margin: 20px 0;
      border: 2px solid #50fa7b;
    }

    .flow-step {
      display: flex;
      align-items: center;
      margin: 10px 0;
      color: #ffb3de;
      font-size: 0.95em;
    }

    .step-num {
      background: #ff79c6;
      color: white;
      width: 30px;
      height: 30px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: bold;
      margin-right: 15px;
      flex-shrink: 0;
    }

    .arrow {
      color: #50fa7b;
      margin: 0 10px;
      font-size: 1.2em;
    }

    .comparison-table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
    }

    .comparison-table th {
      background: #ff79c6;
      color: white;
      padding: 15px;
      text-align: left;
      font-weight: 600;
    }

    .comparison-table td {
      padding: 15px;
      border-bottom: 1px solid #ffb3de;
      color: #ffb3de;
    }

    .comparison-table tr:nth-child(even) {
      background: #19121a;
    }

    .comparison-table tr:nth-child(odd) {
      background: #2a1e28;
    }

    .highlight {
      background: #fff52e;
      color: black;
      padding: 2px 6px;
      border-radius: 3px;
      font-weight: 600;
    }

    .key-point {
      background: #1e1e2f;
      border-left: 5px solid #fff52e;
      padding: 15px;
      margin: 15px 0;
      border-radius: 6px;
      color: #ffb3de;
    }

    .key-point strong {
      color: #fff52e;
    }

    .visual-box {
      background: #19121a;
      border: 2px solid #8be9fd;
      border-radius: 8px;
      padding: 20px;
      margin: 20px 0;
      color: #ffb3de;
    }

    .visual-box h4 {
      color: #8be9fd;
      margin-top: 0;
    }
  </style>
</head>
<body>

<div class="container">
  <h1>üéØ Gradient Descent: Epochs & Batch Size</h1>
  <p class="subtitle">Understanding how training data is processed and weights are updated</p>

  <!-- Gradient Descent Basics -->
  <div class="section">
    <h2>üìö Gradient Descent Basics</h2>
    <p>Gradient Descent is an optimization algorithm that minimizes the loss function by iteratively updating weights in the direction of steepest descent.</p>
    
    <div class="formula">
      W<sub>new</sub> = W<sub>old</sub> - Œ± ¬∑ ‚àáL(W)<br>
      <small style="font-size: 0.8em; margin-top: 10px; display: block;">where Œ± = learning rate, ‚àáL(W) = gradient of loss function</small>
    </div>

    <p style="color: #ffb3de; margin-top: 20px;">Three main variants:</p>
    <div class="example-item">
      <strong>1. Batch Gradient Descent:</strong> Update weights after processing ALL training samples
    </div>
    <div class="example-item">
      <strong>2. Stochastic Gradient Descent (SGD):</strong> Update weights after EACH sample (noisy but fast)
    </div>
    <div class="example-item">
      <strong>3. Mini-Batch SGD:</strong> Update weights after a BATCH of samples (best of both worlds) ‚≠ê
    </div>
  </div>

  <!-- Epochs Explained -->
  <div class="section">
    <h2>üîÅ Epochs: Full Passes Through Data</h2>
    <p><strong>Definition:</strong> An epoch is <span class="highlight">one complete pass through the entire training dataset</span>.</p>

    <div class="key-point">
      <strong>Key Insight:</strong> If you have 10,000 training samples and batch size = 100, you need 100 iterations to complete 1 epoch.
    </div>

    <div class="example-box">
      <h3>üìä Example: Training with 10,000 Samples</h3>
      <div class="example-item">
        <strong>Epoch 1:</strong> Process all 10,000 samples ‚Üí weights updated ‚Üí loss calculated<br>
        <strong>Epoch 2:</strong> Process all 10,000 samples again ‚Üí weights updated ‚Üí loss calculated<br>
        <strong>Epoch 3:</strong> Process all 10,000 samples again ‚Üí weights updated ‚Üí loss calculated<br>
        <span style="color: #50fa7b; margin-top: 10px; display: block;">After 3 epochs, the neural network has "seen" 30,000 samples total</span>
      </div>
    </div>

    <div class="formula">
      Total Iterations = (Total Samples / Batch Size) √ó Epochs<br>
      <small style="font-size: 0.8em; margin-top: 10px; display: block;">Example: (10,000 / 100) √ó 3 = 300 weight updates</small>
    </div>

    <p style="color: #ffb3de; margin-top: 20px;"><strong>‚ö†Ô∏è Too Few Epochs:</strong> Model underfitting (hasn't learned enough)</p>
    <p style="color: #ffb3de;"><strong>‚ö†Ô∏è Too Many Epochs:</strong> Model overfitting (memorizes training data, poor generalization)</p>
  </div>

  <!-- Batch Size Explained -->
  <div class="section">
    <h2>üì¶ Batch Size: Samples Per Update</h2>
    <p><strong>Definition:</strong> The number of training samples processed <span class="highlight">before the weights are updated once</span>.</p>

    <div class="key-point">
      <strong>Key Insight:</strong> Batch size affects how noisy the gradient estimates are and how much memory is required.
    </div>

    <div class="example-box">
      <h3>üîÑ Example: How Batches Work in One Epoch</h3>
      <p style="color: #ffb3de;">Dataset: 1,000 samples | Batch Size: 100</p>
      
      <div class="example-item">
        <strong>Iteration 1:</strong> Process samples 0-99 ‚Üí Gradient update #1<br>
        <strong>Iteration 2:</strong> Process samples 100-199 ‚Üí Gradient update #2<br>
        <strong>Iteration 3:</strong> Process samples 200-299 ‚Üí Gradient update #3<br>
        <strong>...</strong><br>
        <strong>Iteration 10:</strong> Process samples 900-999 ‚Üí Gradient update #10<br>
        <span style="color: #50fa7b; margin-top: 10px; display: block;">‚úì 1 Epoch Complete: 10 iterations, 10 weight updates</span>
      </div>
    </div>

    <table class="comparison-table">
      <thead>
        <tr>
          <th>Batch Size</th>
          <th>Pros</th>
          <th>Cons</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Small (e.g., 16, 32)</strong></td>
          <td>
            ‚úì Noisy gradients escape local minima<br>
            ‚úì More frequent updates<br>
            ‚úì Less memory required
          </td>
          <td>
            ‚úó Unstable convergence<br>
            ‚úó Training slower<br>
            ‚úó High variance in loss
          </td>
        </tr>
        <tr>
          <td><strong>Large (e.g., 256, 512)</strong></td>
          <td>
            ‚úì Stable convergence<br>
            ‚úì Faster iterations<br>
            ‚úì Better GPU utilization
          </td>
          <td>
            ‚úó May get stuck in local minima<br>
            ‚úó More memory required<br>
            ‚úó Fewer updates per epoch
          </td>
        </tr>
      </tbody>
    </table>
  </div>

  <!-- Training Loop Flow -->
  <div class="section">
    <h2>‚öôÔ∏è Complete Training Loop Flow</h2>
    
    <div class="flow-diagram">
      <div class="flow-step">
        <div class="step-num">1</div>
        <div><strong>Load training data</strong> (e.g., 10,000 samples)</div>
      </div>
      <div class="flow-step">
        <div class="step-num">2</div>
        <div><strong>For each EPOCH:</strong> Loop through entire dataset</div>
      </div>
      <div class="flow-step">
        <div class="step-num">3</div>
        <div style="margin-left: 45px;"><strong>Divide dataset into BATCHES</strong> (e.g., batch_size=100)</div>
      </div>
      <div class="flow-step">
        <div class="step-num">4</div>
        <div style="margin-left: 45px;"><strong>For each BATCH:</strong></div>
      </div>
      <div class="flow-step">
        <div style="margin-left: 75px; color: #50fa7b;">
          a) Forward pass: predictions = model(batch)<br>
          b) Calculate loss: L = loss_function(predictions, targets)<br>
          c) Backward pass: compute gradients ‚àÇL/‚àÇW<br>
          d) Weight update: W = W - Œ±¬∑‚àáL(W)
        </div>
      </div>
      <div class="flow-step">
        <div class="step-num">5</div>
        <div><strong>Record epoch loss and validate</strong> (optional)</div>
      </div>
      <div class="flow-step">
        <div class="step-num">6</div>
        <div><strong>Repeat for all epochs</strong></div>
      </div>
    </div>
  </div>

  <!-- Visual Example -->
  <div class="section">
    <h2>üé¨ Visual Training Example</h2>
    
    <div class="visual-box">
      <h4>Scenario: Training with 1,000 samples, Batch Size = 200, Epochs = 3</h4>
      
      <div style="margin-top: 20px; color: #fff52e; font-weight: bold;">EPOCH 1:</div>
      <div style="margin-left: 20px; color: #ffb3de; margin-top: 10px;">
        Batch 1: Samples 0-199 ‚Üí Iteration 1 ‚úì<br>
        Batch 2: Samples 200-399 ‚Üí Iteration 2 ‚úì<br>
        Batch 3: Samples 400-599 ‚Üí Iteration 3 ‚úì<br>
        Batch 4: Samples 600-799 ‚Üí Iteration 4 ‚úì<br>
        Batch 5: Samples 800-999 ‚Üí Iteration 5 ‚úì<br>
        <span style="color: #50fa7b; margin-top: 10px; display: block;">‚Üí 5 weight updates in Epoch 1</span>
      </div>

      <div style="margin-top: 20px; color: #fff52e; font-weight: bold;">EPOCH 2:</div>
      <div style="margin-left: 20px; color: #ffb3de; margin-top: 10px;">
        Batch 1: Samples 0-199 ‚Üí Iteration 6 ‚úì<br>
        Batch 2: Samples 200-399 ‚Üí Iteration 7 ‚úì<br>
        Batch 3: Samples 400-599 ‚Üí Iteration 8 ‚úì<br>
        Batch 4: Samples 600-799 ‚Üí Iteration 9 ‚úì<br>
        Batch 5: Samples 800-999 ‚Üí Iteration 10 ‚úì<br>
        <span style="color: #50fa7b; margin-top: 10px; display: block;">‚Üí 5 weight updates in Epoch 2</span>
      </div>

      <div style="margin-top: 20px; color: #fff52e; font-weight: bold;">EPOCH 3:</div>
      <div style="margin-left: 20px; color: #ffb3de; margin-top: 10px;">
        Batch 1: Samples 0-199 ‚Üí Iteration 11 ‚úì<br>
        Batch 2: Samples 200-399 ‚Üí Iteration 12 ‚úì<br>
        Batch 3: Samples 400-599 ‚Üí Iteration 13 ‚úì<br>
        Batch 4: Samples 600-799 ‚Üí Iteration 14 ‚úì<br>
        Batch 5: Samples 800-999 ‚Üí Iteration 15 ‚úì<br>
        <span style="color: #50fa7b; margin-top: 10px; display: block;">‚Üí 5 weight updates in Epoch 3</span>
      </div>

      <div style="margin-top: 20px; padding: 15px; background: #2a1e28; border-radius: 6px; border-left: 4px solid #fff52e;">
        <strong style="color: #fff52e;">Summary:</strong> <span style="color: #ffb3de;">Total 15 iterations, 15 weight updates, 3 epochs, 3,000 samples processed</span>
      </div>
    </div>
  </div>

  <!-- Python Code Example -->
  <div class="section">
    <h2>üíª Python Implementation Example</h2>
    
    <div class="code-block">
from sklearn.neural_network import MLPClassifier

mlp = MLPClassifier(
    hidden_layer_sizes=(64, 32),
    activation='relu',
    solver='adam',
    batch_size=32,          # ‚Üê Mini-batch SGD: 32 samples per update
    max_iter=200,           # ‚Üê Epochs: 200 full passes through data
    learning_rate_init=0.001,
    random_state=42
)

mlp.fit(X_train, y_train)

# Training Process (internal):
# For each of 200 epochs:
#   Divide X_train into batches of 32
#   For each batch:
#     1. Forward pass
#     2. Calculate loss
#     3. Backward pass (compute gradients)
#     4. Update weights: W -= learning_rate * gradient
    </div>

    <div class="code-block">
# Alternative: More epochs, smaller batch size
mlp = MLPClassifier(
    hidden_layer_sizes=(64, 32),
    batch_size=16,          # ‚Üê Smaller = more updates/epoch, noisier
    max_iter=500,           # ‚Üê More epochs
    learning_rate_init=0.0001,  # ‚Üê Often need lower LR with smaller batches
)
    </div>
  </div>

  <!-- Key Takeaways -->
  <div class="section">
    <h2>üéØ Key Takeaways</h2>
    
    <div class="key-point">
      <strong>Epochs:</strong> Controls how many times the model sees all data. More epochs = longer training, but can lead to better convergence or overfitting.
    </div>

    <div class="key-point">
      <strong>Batch Size:</strong> Controls gradient stability and memory usage. Smaller batches = noisier but faster updates. Larger batches = stable but fewer updates.
    </div>

    <div class="key-point">
      <strong>Relationship:</strong> iterations per epoch = total_samples / batch_size
    </div>

    <div class="key-point">
      <strong>Total Updates:</strong> total_weight_updates = (total_samples / batch_size) √ó epochs
    </div>

    <div class="key-point">
      <strong>Common Practice:</strong> Start with batch_size=32 or 64, epochs=100-200, then tune based on validation performance.
    </div>
  </div>

</div>

</body>
</html>
